{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Team Format and Dataset\n",
    "\n",
    "## 1. Team formation and dataset\n",
    "\n",
    "### 1.1 Contributions\n",
    "\n",
    "- Oswald Lackner\n",
    "    - Initial python script setup\n",
    "    - Plot activation\n",
    "    - Column data managment\n",
    "    - Import of raw data from CSV-files\n",
    "    - Dataset overview\n",
    "    - Data processing pipline (cleaning, outlier)\n",
    "        - Hexbin raw data visualisation\n",
    "            - Hours of day\n",
    "            - Days a week\n",
    "            - days a year\n",
    "        - Outlier removal\n",
    "- Stocker Christoph\n",
    "    - Basic statistical analysis\n",
    "    - Original data quality analysis with visualization\n",
    "        - Checking Dataset Time Ranges\n",
    "        - Generating Combined Missingness diagramm\n",
    "        - Generating Combined Timestamp Gap Analysis\n",
    "        - Generating Combined Outlier Analysis\n",
    "        - Generating Logical Consistency Check\n",
    "\n",
    "Source of Data: [Kaggle: Hourly Power Generation of Europe](https://www.kaggle.com/datasets/mehmetnuryildirim/hourly-power-generation-of-europe) (date: 2026-01-16)\n",
    "\n",
    "# 2. Task Categories and Points\n",
    "\n",
    "## 2.1 A. Data Preprocessing and Data Quality (70 points)\n",
    "\n",
    "1. Dataset overview (dimensions, columns, types, time range, sampling rate, missingness\n",
    "summary) (10 points)\n",
    "2. Basic statistical analysis using pandas (descriptives, grouped stats, quantiles) (10 points)\n",
    "3. Original data quality analysis with visualization (missingness patterns, outliers, dupli-\n",
    "cates, timestamp gaps, inconsistent units) (20 points)\n",
    "4. Data preprocessing pipeline (cleaning steps, handling missing data, outliers strategy, re-\n",
    "sampling or alignment if needed, feature engineering basics) (20 points)\n",
    "5. Preprocessed vs original comparison (before/after visuals plus commentary on what changed\n",
    "and why) (10 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### 2.1.1 Dataset overview (dimensions, columns, types, time range, sampling rate, missingness summary) (10 points)\n",
    "\n",
    "This section is about data impoert and preprocessing\n",
    "\n",
    "1. Initial python script setup\n",
    "2. Class for activated plots\n",
    "3. Class for Columns of Data\n",
    "4. Import of CSV-files\n",
    "\n",
    "### 2.1.1.1 Initial python script setup\n",
    "\n",
    "Import of main librarys an basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from enum import Enum, auto\n",
    "import calendar\n",
    "from typing import Iterable, Tuple, Dict, Union\n",
    "import matplotlib.colors as mcolors\n",
    "import pprint\n",
    "\n",
    "\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': [12, 8],\n",
    "    'figure.dpi': 150,\n",
    "    'figure.autolayout': True,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'font.size': 12\n",
    "})\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 2.1.1.2 Class for activated plots\n",
    "\n",
    "This class shall provide a basic mechanism to activate/deactivate plots and calculation for analyze parts in shorter time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotOptions(Enum):\n",
    "    DATAFRAME_NAN_REPORT = auto()\n",
    "    TIME_PLOT_RAW_POWER = auto()\n",
    "    TIME_PLOT_RAW_POWER_OVERLAY = auto()\n",
    "    POWER_SHARE_BY_SOURCE = auto()\n",
    "    POWER_SHARE_BY_SOURCE_OVER_YEARS = auto()\n",
    "    SCATTER_TOTAL_POWER_OVER_YEAR = auto()\n",
    "    YEARLY_SEASONAL_OVER_YEARS = auto()\n",
    "    HOURLY_PLOT_OVER_SEASONS = auto()\n",
    "    HEXBIN_TOTAL_POWER_HOURLY_DAYTIME_PLOT = auto()\n",
    "    HEXBIN_TOTAL_POWER_DAILY_YEAR_PLOT = auto()\n",
    "    HOURLY_TOTAL_POWER_REGRESSION = auto()\n",
    "    TREND_TOTAL_POWER_OVER_YEARS = auto()\n",
    "    TREND_TOTAL_POWER_OVER_MONTHS = auto()\n",
    "\n",
    "class StatesOptions(Enum):\n",
    "    ITALY = auto()\n",
    "    FRANCE = auto()\n",
    "    GERMANY = auto()\n",
    "    SPAIN = auto()    \n",
    "\n",
    "class ActvnMatrix:\n",
    "    PLOT_OPTIONS_DICT = {\n",
    "        \"DATAFRAME_NAN_REPORT\": True,\n",
    "        \"TIME_PLOT_RAW_POWER\": True,\n",
    "        \"TIME_PLOT_RAW_POWER_OVERLAY\": False,\n",
    "        \"POWER_SHARE_BY_SOURCE\": True,\n",
    "        \"POWER_SHARE_BY_SOURCE_OVER_YEARS\": True,\n",
    "        \"SCATTER_TOTAL_POWER_OVER_YEAR\": True,\n",
    "        \"YEARLY_SEASONAL_OVER_YEARS\": True,\n",
    "        \"HOURLY_PLOT_OVER_SEASONS\": False,\n",
    "        \"HEXBIN_TOTAL_POWER_HOURLY_DAYTIME_PLOT\": True,\n",
    "        # \"HEXBIN_TOTAL_POWER_HOURLY_DAYTIME_PLOT\": False,\n",
    "        \"HEXBIN_TOTAL_POWER_DAILY_YEAR_PLOT\": False,\n",
    "        # \"HEXBIN_TOTAL_POWER_DAILY_YEAR_PLOT\": True\n",
    "        \"HOURLY_TOTAL_POWER_REGRESSION\" : True,\n",
    "        \"TREND_TOTAL_POWER_OVER_YEARS\": True,\n",
    "        \"TREND_TOTAL_POWER_OVER_MONTHS\": True\n",
    "    }\n",
    "\n",
    "    STATE = {\n",
    "        \"Italy\": True,\n",
    "        \"France\": True,\n",
    "        \"Germany\": True,\n",
    "        \"Spain\": True,\n",
    "    } \n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def is_active(cls, country: str, plot_option: PlotOptions) -> bool:\n",
    "        \"\"\"\n",
    "        Return True if the given country and plot_option are active.\n",
    "        country can be:\n",
    "            - string (case-insensitive)\n",
    "            - StatesOptions enum\n",
    "        plot_option can be:\n",
    "            - string (case-insensitive)\n",
    "            - PlotOptions enum\n",
    "        Prints messages if country or plot is inactive.\n",
    "        \"\"\"\n",
    "        country_str = country\n",
    "        plot_str = plot_option.name\n",
    "        # --- Check country ---\n",
    "        if country_str not in cls.STATE:\n",
    "            print(f\"\\n{'!'*10} WARNING {'!'*10}\")\n",
    "            print(f\"Country '{country_str}' not found in STATE dictionary!\")\n",
    "            return False\n",
    "\n",
    "        country_active = cls.STATE[country_str]\n",
    "\n",
    "        # --- Check plot ---\n",
    "        plot_active = cls.PLOT_OPTIONS_DICT.get(plot_str, False)\n",
    "        if not plot_active:\n",
    "            print(f\"\\n{'-'*5} NOTE {'-'*5}\")\n",
    "            print(f\"Plot '{plot_str}' is deactivated in PLOT_OPTIONS_DICT. Skipping execution for {country_str}.\")\n",
    "            return False\n",
    "\n",
    "        return country_active and plot_active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 2.1.1.3 Class for Columns of Data\n",
    "\n",
    "This class shall provide all columns of data in an effective way to use environments variable fullfillment and additional it shall prevent typos for column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Columns:\n",
    "    AREA = 'Area'\n",
    "    MTU = 'MTU'\n",
    "    DATETIME = 'DATETIME'\n",
    "    YEAR = 'YEAR'\n",
    "\n",
    "    META = [\n",
    "        AREA,\n",
    "        MTU,\n",
    "        DATETIME,\n",
    "        YEAR\n",
    "    ]\n",
    "\n",
    "    class Power:\n",
    "        # Standard main types\n",
    "        BIOMASS = 'Biomass - Actual Aggregated [MW]'\n",
    "        FOSSIL_BROWN = 'Fossil Brown coal/Lignite - Actual Aggregated [MW]'\n",
    "        FOSSIL_COAL_DERIVED_GAS = 'Fossil Coal-derived gas - Actual Aggregated [MW]'\n",
    "        FOSSIL_GAS = 'Fossil Gas - Actual Aggregated [MW]'\n",
    "        FOSSIL_HARD_COAL = 'Fossil Hard coal - Actual Aggregated [MW]'\n",
    "        FOSSIL_OIL = 'Fossil Oil - Actual Aggregated [MW]'\n",
    "        FOSSIL_OIL_SHALE = 'Fossil Oil shale - Actual Aggregated [MW]'\n",
    "        FOSSIL_PEAT = 'Fossil Peat - Actual Aggregated [MW]'\n",
    "        GEOTHERMAL = 'Geothermal - Actual Aggregated [MW]'\n",
    "        HYDRO_PUMPED = 'Hydro Pumped Storage - Actual Aggregated [MW]'\n",
    "        HYDRO_CONSUMPTION = 'Hydro Pumped Storage - Actual Consumption [MW]'\n",
    "        HYDRO_RUNOF = 'Hydro Run-of-river and poundage - Actual Aggregated [MW]'\n",
    "        HYDRO_RESERVOIR = 'Hydro Water Reservoir - Actual Aggregated [MW]'\n",
    "        MARINE = 'Marine - Actual Aggregated [MW]'\n",
    "        NUCLEAR = 'Nuclear - Actual Aggregated [MW]'\n",
    "        OTHER = 'Other - Actual Aggregated [MW]'\n",
    "        OTHER_RENEWABLE = 'Other renewable - Actual Aggregated [MW]'\n",
    "        SOLAR = 'Solar - Actual Aggregated [MW]'\n",
    "        WASTE = 'Waste - Actual Aggregated [MW]'\n",
    "        WIND_OFFSHORE = 'Wind Offshore - Actual Aggregated [MW]'\n",
    "        WIND_ONSHORE = 'Wind Onshore - Actual Aggregated [MW]'\n",
    "\n",
    "        # Helper: list of all known power columns\n",
    "        ALL = [\n",
    "            BIOMASS, FOSSIL_BROWN, FOSSIL_COAL_DERIVED_GAS, FOSSIL_GAS,\n",
    "            FOSSIL_HARD_COAL, FOSSIL_OIL, FOSSIL_OIL_SHALE, FOSSIL_PEAT,\n",
    "            GEOTHERMAL, HYDRO_PUMPED, HYDRO_CONSUMPTION, HYDRO_RUNOF, HYDRO_RESERVOIR,\n",
    "            MARINE, NUCLEAR, OTHER, OTHER_RENEWABLE, SOLAR, WASTE,\n",
    "            WIND_OFFSHORE, WIND_ONSHORE\n",
    "        ]\n",
    "\n",
    "        ALL_FILT = [\n",
    "            BIOMASS, FOSSIL_BROWN, FOSSIL_COAL_DERIVED_GAS, FOSSIL_GAS,\n",
    "            FOSSIL_HARD_COAL, FOSSIL_OIL,\n",
    "            GEOTHERMAL, HYDRO_PUMPED, HYDRO_CONSUMPTION, HYDRO_RUNOF, HYDRO_RESERVOIR,\n",
    "            NUCLEAR, OTHER, SOLAR, WASTE,\n",
    "            WIND_ONSHORE\n",
    "        ] # Removed: FOSSIL_OIL_SHALE,  FOSSIL_PEAT, MARINE, WIND_OFFSHORE, OTHER_RENEWABLE, \n",
    "\n",
    "    \n",
    "\n",
    "        HYDRO = [\n",
    "            HYDRO_PUMPED, HYDRO_CONSUMPTION, HYDRO_RUNOF, HYDRO_RESERVOIR\n",
    "        ]\n",
    "\n",
    "        WIND = [\n",
    "            WIND_ONSHORE\n",
    "        ] # WIND_OFFSHORE,\n",
    "\n",
    "        FOSSIL = [\n",
    "            FOSSIL_BROWN, FOSSIL_COAL_DERIVED_GAS, FOSSIL_GAS,\n",
    "            FOSSIL_HARD_COAL, FOSSIL_OIL,\n",
    "        ] # FOSSIL_OIL_SHALE,  FOSSIL_PEAT\n",
    "\n",
    "        RENEWAABLE = [\n",
    "            BIOMASS, GEOTHERMAL, HYDRO_PUMPED, HYDRO_CONSUMPTION, HYDRO_RUNOF,\n",
    "            HYDRO_RESERVOIR, SOLAR, WIND_ONSHORE\n",
    "        ] # Removed:  OTHER_RENEWABLE, WIND_OFFSHORE, MARINE,\n",
    "\n",
    "    # Additional calculated columns\n",
    "    class CALC:\n",
    "        # Axis columns\n",
    "        TOTAL_POWER = 'total_power'\n",
    "        TOTAL_FOSSIL_POWER = 'total_fossil_power'\n",
    "        TOTAL_RENEWABLE_POWER = 'total_renewable_power'\n",
    "\n",
    "    # Additional columns as Axis representations\n",
    "    class AXIS:\n",
    "        DAY_OF_WEEK = 'day_of_week'\n",
    "        DAY_OF_YEAR = 'day_in_year'\n",
    "        SEASON = 'season'\n",
    "        YEAR  = 'year'\n",
    "        MONTH = 'month'\n",
    "        MONTH_STR = 'month_str'\n",
    "        DAY_OF_WEEK_STR = 'day_of_week_str'\n",
    "        HOURS_OF_DAY = 'hours_a_day'\n",
    "\n",
    "\n",
    "colors = {\n",
    "    \"Italy\": \"tab:blue\",\n",
    "    \"France\": \"tab:orange\",\n",
    "    \"Germany\": \"tab:green\",\n",
    "    \"Spain\": \"tab:red\",\n",
    "}        \n",
    "\n",
    "\n",
    "WEEK_ORDER = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "MONTH_ORDER = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.1.1.4 Import of raw data from CSV-files\n",
    "\n",
    "Dataset is provided by 4 individual csv-files containing same columns. These datasets are imported by reusing the function:\n",
    "```python\n",
    "def load_power_generation_data(...) -> pd.DataFrame:\n",
    "```\n",
    "\n",
    "Dataset is available in 4 seperate files:\n",
    "\n",
    "- File for Italy: `Italy_Power_Generation.csv`\n",
    "- File for France: `France_Power_Generation.csv`\n",
    "- File for Germany: `Germany_Power_Generation.csv`\n",
    "- File for Spain: `Spain_Power_Generation.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_power_generation_data(file_path: str, dataset_name: str, col_datetime: str = 'DATETIME') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and process power generation data from a CSV file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Path to the CSV data file\n",
    "    col_datetime : str\n",
    "        Column name to use as datetime index (default 'DATETIME')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Processed DataFrame with:\n",
    "        - DatetimeIndex from MTU column\n",
    "        - Numeric power columns\n",
    "        - Columns normalized to match Columns class\n",
    "    \"\"\"\n",
    "\n",
    "    filepath = Path(file_path)\n",
    "    print(\"\\n\\n\" + \"=\" * 100)\n",
    "    print(f\"Loading data from:\")\n",
    "    print(f\"    - Path: {filepath.parent}\")\n",
    "    print(f\"    - File: {filepath.name}\\n\")\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    print(f\"\\nColumn of {dataset_name}\" + 45*\" \"+ \"Number of NaNs\")\n",
    "    print(80*\"-\")\n",
    "    print(df.isna().sum().sort_values(ascending=False))\n",
    "\n",
    "    # Normalize column names (make number of spaces consistent)\n",
    "    df.columns = df.columns.str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    # Fix Germany-specific DATETIME\n",
    "    if col_datetime not in df.columns:\n",
    "        if 'Unnamed: 2' in df.columns:\n",
    "            df.rename(columns={'Unnamed: 2': col_datetime}, inplace=True)\n",
    "        else:\n",
    "            raise KeyError(f\"{col_datetime} column not found in {filepath.name}\")\n",
    "\n",
    "    # Extract first datetime from MTU\n",
    "    if 'MTU' in df.columns:\n",
    "        df[col_datetime] = df['MTU'].str.split(' - ').str[0]\n",
    "    else:\n",
    "        raise KeyError(\"MTU column not found for datetime extraction\")\n",
    "\n",
    "    # Convert to datetime\n",
    "    df[col_datetime] = pd.to_datetime(df[col_datetime], format='%d.%m.%Y %H:%M', errors='coerce')\n",
    "\n",
    "    # Safety check\n",
    "    if df[col_datetime].isna().any():\n",
    "        print(f\"Warning: Some rows could not be converted to datetime in {filepath.name}\")\n",
    "\n",
    "    # Set index\n",
    "    df.set_index(col_datetime, inplace=True)\n",
    "\n",
    "    # Identify power columns present in the CSV (intersection with Columns.Power.ALL)\n",
    "    power_cols = [c for c in Columns.Power.ALL if c in df.columns]\n",
    "\n",
    "    # Convert all power columns to numeric\n",
    "    df[power_cols] = df[power_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Calculate total power generation\n",
    "    df[Columns.CALC.TOTAL_POWER] = df[Columns.Power.ALL].sum(axis=1)\n",
    "    df[Columns.CALC.TOTAL_FOSSIL_POWER] = df[Columns.Power.FOSSIL].sum(axis=1)\n",
    "    df[Columns.CALC.TOTAL_RENEWABLE_POWER] = df[Columns.Power.RENEWAABLE].sum(axis=1)\n",
    "\n",
    "\n",
    "    # Create additional time-based columns\n",
    "    df[Columns.AXIS.YEAR] = df.index.year\n",
    "\n",
    "    # Month + fractional day\n",
    "    df[Columns.AXIS.MONTH] = df.index.month + (df.index.day - 1) / df.index.days_in_month\n",
    "    # df[Columns.AXIS.MONTH] = df.index.month\n",
    "\n",
    "    # Day of year + fractional day\n",
    "    df[Columns.AXIS.DAY_OF_YEAR] = df.index.dayofyear + (df.index.hour + df.index.minute / 60) / 24\n",
    "    # df[Columns.AXIS.DAY_OF_YEAR] = df.index.dayofyear\n",
    "\n",
    "    # Day of week + fractional day\n",
    "    df[Columns.AXIS.DAY_OF_WEEK] = df.index.dayofweek + (df.index.hour + df.index.minute / 60) / 24\n",
    "    #df[Columns.AXIS.DAY_OF_WEEK] = df.index.dayofweek\n",
    "\n",
    "    season_map = {\n",
    "        12: \"Winter\", 1: \"Winter\", 2: \"Winter\",\n",
    "        3: \"Spring\", 4: \"Spring\", 5: \"Spring\",\n",
    "        6: \"Summer\", 7: \"Summer\", 8: \"Summer\",\n",
    "        9: \"Autumn\", 10: \"Autumn\", 11: \"Autumn\"\n",
    "    }\n",
    "\n",
    "    # df[Columns.AXIS.SEASON] = df[Columns.AXIS.MONTH].map(season_map) -> doesn't work with fractional months\n",
    "    df[Columns.AXIS.SEASON] = df.index.month.map(season_map)\n",
    "\n",
    "    #df[Columns.AXIS.MONTH_STR] = df[Columns.AXIS.MONTH].apply(lambda x: calendar.month_name[x])\n",
    "    df[Columns.AXIS.MONTH_STR] = df[Columns.AXIS.MONTH].apply(lambda x: calendar.month_name[int(np.floor(x))])\n",
    "\n",
    "    df[Columns.AXIS.DAY_OF_WEEK_STR] = df[Columns.AXIS.DAY_OF_WEEK].apply(lambda x: calendar.day_name[int(np.floor(x))])\n",
    "    df[Columns.AXIS.HOURS_OF_DAY] = df.index.hour + df.index.minute / 60\n",
    "\n",
    "\n",
    "    print(\"\\nShape:\")\n",
    "    print(f\"  Rows: {df.shape[0]:,}\")\n",
    "    print(f\"  Columns: {df.shape[1]}\\n\")\n",
    "\n",
    "    #print(f\"\\nTime range: {df.index.min()} to {df.index.max()}\")\n",
    "    #print(f\"Number of samples: {len(df):,}\")\n",
    "\n",
    "    # print(\"\\nColumns:\")\n",
    "    # for col in df.columns:\n",
    "    #     print(f\"  - {col}\")\n",
    "\n",
    "    #print(\"\\nFirst few rows:\")\n",
    "    #print(df.head())\n",
    "\n",
    "    print(\"Data Overview:\")\n",
    "    print(df.describe())    \n",
    "\n",
    "    # print(\"\\nMissing values per column:\")\n",
    "    # print(df.isna().sum().sort_values(ascending=False))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 2.1.1.5 Load function overview\n",
    "\n",
    "\n",
    "These files are read in by using function:\n",
    "```python\n",
    "def load_power_generation_data(file_path: str, col_datetime: str = 'DATETIME') -> pd.DataFrame:\n",
    "```\n",
    "\n",
    "Funtions of `load_power_generation_data`:\n",
    "\n",
    "- List Read in file with path.\n",
    "- normalize the number of spaces to be usable over all dataset parts\n",
    "- count number of NaNs\n",
    "- especially Germany has a datetime column that is not named. -> 2.1.4 Data preprocessing pipeline\n",
    "- extraction of datetime from MTU column which is state. -> 2.1.4 Data preprocessing pipeline\n",
    "- convert MTU daytime extracted to python datatype datetime -> 2.1.4 Data preprocessing pipeline\n",
    "- check for correct convertion by counting possible NaNs -> 2.1.4 Data preprocessing pipeline\n",
    "- set extracted datetime to index.  -> 2.1.4 Data preprocessing pipeline\n",
    "- catch  power cols for dataset\n",
    "- convert power columns to numeric -> 2.1.4 Data preprocessing pipeline\n",
    "- calculate total power -> 2.1.4 Data preprocessing pipeline\n",
    "- create addional timely indexes for year, month, day of the year, day of the week, hours of the day\n",
    "- Add seasonal information\n",
    "- Add Monthly/weekly time information as string\n",
    "\n",
    "Print information of data\n",
    "- Print number of rows, columns\n",
    "- Dataframe describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.cwd()\n",
    "subfolder = Path(r\"OneDrive - FH JOANNEUM\\Courses\\STM_WS2025_DA_Data Analysis\\Assignment_2\")\n",
    "#subfolder = Path(r\"C:\\Users\\chris\\FH JOANNEUM\\Lackner Oswald - Assignment_2\")\n",
    "#subfolder = Path(r\"data\")  # <-- For venv testing in github repository\n",
    "\n",
    "COUNTRIES = [\"Italy\", \"France\", \"Germany\", \"Spain\"]\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for country in COUNTRIES:\n",
    "    df = load_power_generation_data(\n",
    "        file_path=base_path / subfolder / f\"{country}_Power_Generation.csv\",\n",
    "        dataset_name=country\n",
    "    )\n",
    "    dataframes.append((country, df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### 2.1.1.6 Dataset overview\n",
    "\n",
    "Dataset overview (dimensions, columns, types, time range, sampling rate, missingness\n",
    "summary) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_multiple_dataframe_overview(\n",
    "    dataframes: list[tuple[str, pd.DataFrame]],\n",
    "    datetime_col: str | None = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Print a Markdown-style overview and comparison of multiple DataFrames.\n",
    "\n",
    "    Includes:\n",
    "    - Dimensions\n",
    "    - Column data types\n",
    "    - Time range\n",
    "    - Sampling rate\n",
    "    - Missingness summary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframes : list of (name, DataFrame)\n",
    "    datetime_col : str or None\n",
    "        Column name for datetime, or None if DatetimeIndex is used.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n# Dataset Comparison Overview\\n\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # DATASET-LEVEL OVERVIEW TABLE\n",
    "    # ----------------------------\n",
    "    header = (\n",
    "        \"| Dataset | Rows | Columns | Time Start | Time End | Sampling Rate | Missing Cells | Missing % |\"\n",
    "    )\n",
    "    separator = (\n",
    "        \"|---------|------|---------|------------|----------|---------------|---------------|-----------|\"\n",
    "    )\n",
    "\n",
    "    print(header)\n",
    "    print(separator)\n",
    "\n",
    "    for name, df in dataframes:\n",
    "        rows, cols = df.shape\n",
    "\n",
    "        # ---- datetime handling ----\n",
    "        dt = None\n",
    "        if datetime_col and datetime_col in df.columns:\n",
    "            dt = pd.to_datetime(df[datetime_col], errors=\"coerce\")\n",
    "        elif isinstance(df.index, pd.DatetimeIndex):\n",
    "            dt = df.index\n",
    "\n",
    "        if dt is not None and not dt.dropna().empty:\n",
    "            t_start = dt.min()\n",
    "            t_end = dt.max()\n",
    "\n",
    "            diffs = dt.sort_values().diff().dropna()\n",
    "            sampling = diffs.median() if len(diffs) else \"N/A\"\n",
    "\n",
    "        else:\n",
    "            t_start = t_end = sampling = \"N/A\"\n",
    "\n",
    "        # ---- missingness ----\n",
    "        missing_cells = df.isna().sum().sum()\n",
    "        missing_pct = (missing_cells / (rows * cols)) * 100 if rows * cols else 0\n",
    "\n",
    "        print(\n",
    "            f\"| {name} | \"\n",
    "            f\"{rows:,} | \"\n",
    "            f\"{cols} | \"\n",
    "            f\"{t_start} | \"\n",
    "            f\"{t_end} | \"\n",
    "            f\"{sampling} | \"\n",
    "            f\"{missing_cells:,} | \"\n",
    "            f\"{missing_pct:.2f}% |\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # COLUMN-LEVEL DETAILS\n",
    "    # ----------------------------\n",
    "    for name, df in dataframes:\n",
    "        print(f\"## Column Details – {name}\\n\")\n",
    "\n",
    "        col_header = \"| Column | dtype | Missing | Missing % |\"\n",
    "        col_sep = \"|--------|-------|---------|-----------|\"\n",
    "\n",
    "        print(col_header)\n",
    "        print(col_sep)\n",
    "\n",
    "        total_rows = len(df)\n",
    "\n",
    "        for col in df.columns:\n",
    "            missing = df[col].isna().sum()\n",
    "            missing_pct = (missing / total_rows) * 100 if total_rows else 0\n",
    "\n",
    "            print(\n",
    "                f\"| {col} | \"\n",
    "                f\"{df[col].dtype} | \"\n",
    "                f\"{missing:,} | \"\n",
    "                f\"{missing_pct:.2f}% |\"\n",
    "            )\n",
    "\n",
    "        print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "report_multiple_dataframe_overview(dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_nan_report(df: pd.DataFrame, max_examples: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a detailed NaN and dtype report for a DataFrame.\n",
    "    \"\"\"\n",
    "    report = []\n",
    "\n",
    "    total_rows = len(df)\n",
    "\n",
    "    for col in df.columns:\n",
    "        na_count = df[col].isna().sum()\n",
    "\n",
    "        if na_count > 0:\n",
    "            example_idx = df[df[col].isna()].index[:max_examples].tolist()\n",
    "        else:\n",
    "            example_idx = []\n",
    "\n",
    "        report.append({\n",
    "            \"column\": col,\n",
    "            \"dtype\": df[col].dtype,\n",
    "            \"is_numeric\": pd.api.types.is_numeric_dtype(df[col]),\n",
    "            #\"rows\": total_rows,\n",
    "            \"na_count\": na_count,\n",
    "            \"na_percent\": round(na_count / total_rows * 100, 2),\n",
    "            \"example_na_indices\": example_idx\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(report).sort_values(\"na_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for country, df in dataframes:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.DATAFRAME_NAN_REPORT):\n",
    "        continue\n",
    "    report = dataframe_nan_report(df)\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nNaN Report for {country}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(report)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nan_summary_table(\n",
    "    dataframes: list[tuple[str, pd.DataFrame]],\n",
    "    power_column_keywords=(\"Actual Aggregated\", \"Actual Consumption\"),\n",
    "    add_total: bool = True,\n",
    "    sort_by_total: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a NaN summary table for power source columns across multiple countries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframes : list of (str, pd.DataFrame)\n",
    "        List of (country_name, DataFrame)\n",
    "    power_column_keywords : tuple\n",
    "        Keywords used to identify power-related columns\n",
    "    add_total : bool\n",
    "        Whether to add a Total_NaNs column\n",
    "    sort_by_total : bool\n",
    "        Whether to sort by Total_NaNs descending\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        NaN summary table (rows = power sources, columns = countries)\n",
    "    \"\"\"\n",
    "\n",
    "    nan_counts = {}\n",
    "\n",
    "    for country, df in dataframes:\n",
    "        power_cols = [\n",
    "            col for col in df.columns\n",
    "            if any(keyword in col for keyword in power_column_keywords)\n",
    "        ]\n",
    "\n",
    "        nan_counts[country] = df[power_cols].isna().sum()\n",
    "\n",
    "    nan_table = pd.DataFrame(nan_counts).fillna(0).astype(int)\n",
    "\n",
    "    if add_total:\n",
    "        nan_table[\"Total_NaNs\"] = nan_table.sum(axis=1)\n",
    "\n",
    "    if sort_by_total and \"Total_NaNs\" in nan_table.columns:\n",
    "        nan_table = nan_table.sort_values(\"Total_NaNs\", ascending=False)\n",
    "\n",
    "    return nan_table\n",
    "\n",
    "nan_summary_table = build_nan_summary_table(dataframes=dataframes)\n",
    "print(\"\\nNaN Summary Table:\")\n",
    "print(nan_summary_table.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_raw_dataset_overview(\n",
    "    df: pd.DataFrame,\n",
    "    name: str = \"Dataset\",\n",
    "    datetime_col: str | None = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Print a overview report of a raw dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n#  Dataset Overview: {name}\\n\")\n",
    "\n",
    "    # ---- Dimensions ----\n",
    "    print(\"## Dimensions\")\n",
    "    print(f\"- Rows: **{df.shape[0]:,}**\")\n",
    "    print(f\"- Columns: **{df.shape[1]}**\\n\")\n",
    "\n",
    "    # ---- Column info ----\n",
    "    print(\"## Columns & Data Types\")\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        print(f\"- `{col}` → `{dtype}`\")\n",
    "    print()\n",
    "\n",
    "    # ---- Datetime handling ----\n",
    "    dt_series = None\n",
    "    if datetime_col and datetime_col in df.columns:\n",
    "        dt_series = pd.to_datetime(df[datetime_col], errors=\"coerce\")\n",
    "    elif isinstance(df.index, pd.DatetimeIndex):\n",
    "        dt_series = df.index\n",
    "\n",
    "    if dt_series is not None and not dt_series.dropna().empty:\n",
    "        print(\"## Time Coverage\")\n",
    "        print(f\"- Start: **{dt_series.min()}**\")\n",
    "        print(f\"- End: **{dt_series.max()}**\")\n",
    "\n",
    "        # Sampling rate estimation\n",
    "        diffs = dt_series.sort_values().diff().dropna()\n",
    "        if not diffs.empty:\n",
    "            most_common = pd.Series(diffs).mode().iloc[0]\n",
    "            print(f\"- Estimated sampling rate: **{most_common}**\")\n",
    "        print()\n",
    "    else:\n",
    "        print(\"## Time Coverage\")\n",
    "        print(\"- No valid datetime information found\\n\")\n",
    "\n",
    "    # ---- Missingness ----\n",
    "    print(\"## Missing Values Summary\")\n",
    "    na_counts = df.isna().sum()\n",
    "    na_percent = (na_counts / len(df)) * 100\n",
    "\n",
    "    has_missing = False\n",
    "    for col in df.columns:\n",
    "        if na_counts[col] > 0:\n",
    "            has_missing = True\n",
    "            print(\n",
    "                f\"- `{col}`: \"\n",
    "                f\"{na_counts[col]:,} missing \"\n",
    "                f\"({na_percent[col]:.2f}%)\"\n",
    "            )\n",
    "\n",
    "    if not has_missing:\n",
    "        print(\"- No missing values detected\")\n",
    "\n",
    "    print(\"\\n---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for country, df in dataframes:\n",
    "    # if not ActvnMatrix.is_active(country, PlotOptions.DATAFRAME_NAN_REPORT):\n",
    "    #     continue\n",
    "    report_raw_dataset_overview(df, name=country + \" – Raw Power Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### 2.1.2 Basic statistical analysis using pandas (descriptives, grouped stats, quantiles) (10 points)\n",
    "\n",
    "    - descriptives (mean, std deviation, min/max)\n",
    "    - stats Total power by season / year\n",
    "    - quantiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_basic_stats(df: pd.DataFrame, country: str):\n",
    "    \"\"\"\n",
    "    Returns the full descriptive statistics (transposed) for the country.\n",
    "    \"\"\"\n",
    "    # numeric power + total power (ignore date, text ect)\n",
    "    stats_cols = [c for c in Columns.Power.ALL + [Columns.CALC.TOTAL_POWER] if c in df.columns]\n",
    "    \n",
    "    # calculate non missin rows, mean, standard devaiton, min, max, and quatiles\n",
    "    desc_stats = df[stats_cols].describe().round(2).T\n",
    "    \n",
    "    # return clean and transponated table\n",
    "    return desc_stats[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]\n",
    "\n",
    "# execute\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "all_country_stats = {}\n",
    "total_power_overview = {}\n",
    "\n",
    "# loop all counties\n",
    "for country, df in dataframes:\n",
    "    stats = perform_basic_stats(df, country)\n",
    "    # save all satistics into a dictionary\n",
    "    all_country_stats[country] = stats      \n",
    "    \n",
    "    # extract total power for overview\n",
    "    if Columns.CALC.TOTAL_POWER in stats.index:\n",
    "        total_power_overview[country] = stats.loc[Columns.CALC.TOTAL_POWER]\n",
    "\n",
    "# 1 overview of total power\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. OVERVIEW: TOTAL POWER GENERATION STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "# output the total power data\n",
    "overview_df = pd.DataFrame(total_power_overview)\n",
    "print(overview_df)\n",
    "\n",
    "# 2 display all sources \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. DETAILED COMPARISON (ALL POWER SOURCES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# combine all the stats tables\n",
    "comparative_df = pd.concat(all_country_stats.values(), axis=1, keys=all_country_stats.keys())\n",
    "\n",
    "# flip the colum hierachy for better readability\n",
    "comparative_df = comparative_df.swaplevel(0, 1, axis=1).sort_index(axis=1)\n",
    "\n",
    "# define output order\n",
    "metrics_to_show = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "\n",
    "# print out the rest of the data\n",
    "for metric in metrics_to_show:\n",
    "    if metric in comparative_df.columns.get_level_values(0):\n",
    "        print(f\"\\n{'-'*30} {metric.upper()} {'-'*30}\")\n",
    "        print(comparative_df[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 2.1.3 Original data quality analysis with visualization  (20 points)\n",
    "\n",
    "- missingness patterns\n",
    "- outliers\n",
    "- duplicates\n",
    "- timestamp gaps\n",
    "- inconsistent units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_quality_combined(dataframes_list):\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Original data quality analysis\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # extract the names\n",
    "    countries = [name for name, _ in dataframes_list]\n",
    "    \n",
    "\n",
    "    # ------------------------ time range ------------------------\n",
    "    # check the ranges\n",
    "    # the measurement start dates of the countries are different\n",
    "    # thus the index has to be adapted\n",
    "    print(\"\\ncheck time range\")\n",
    "    range_data = []\n",
    "    for country, df in dataframes_list:\n",
    "        range_data.append({\n",
    "            \"Country\": country,\n",
    "            \"Start Date\": df.index.min(),\n",
    "            \"End Date\": df.index.max(),\n",
    "            \"Total Days\": (df.index.max() - df.index.min()).days        # duration\n",
    "        })\n",
    "    # display the date information\n",
    "    print(pd.DataFrame(range_data).set_index(\"Country\"))\n",
    "\n",
    "\n",
    "    # ------------------------ missingness diagram ------------------------\n",
    "    print(\"\\nmissingness diagram\")\n",
    "    # Added sharex=False to allow for different start/end dates\n",
    "    n_plots = len(dataframes_list)\n",
    "    fig, axes = plt.subplots(n_plots, 1, figsize=(15, 5*n_plots), sharex=False)\n",
    "    if n_plots == 1: axes = [axes]\n",
    "\n",
    "    # generate the height and pairs the plot with the corresponding data\n",
    "    for ax, (country, df) in zip(axes, dataframes_list):\n",
    "        sns.heatmap(\n",
    "            df.isnull().T,      # create a table for the missing data\n",
    "            ax=ax, \n",
    "            cbar=False,         # disable the legend\n",
    "            cmap='viridis',     # set colors to yellow and purple (visibility)\n",
    "            xticklabels=False, \n",
    "            yticklabels=True\n",
    "        )\n",
    "        # set titles\n",
    "        ax.set_title(f\"{country} – Missing Data (Yellow = Missing)\", fontsize=14, loc='left', pad=10)\n",
    "        ax.tick_params(axis='y', rotation=0, labelsize=10)\n",
    "        \n",
    "        # added display of start and end time (because of different start end end dates of the data)\n",
    "        start_str = str(df.index.min().date())\n",
    "        end_str = str(df.index.max().date())\n",
    "        ax.set_xlabel(f\"Timeline: {start_str} to {end_str}\", fontsize=10, color='gray')\n",
    "    \n",
    "    # generate the plot\n",
    "    plt.suptitle(\"Missing Data Patterns Overview \", fontsize=16, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # ------------------------ timestamp gaps ------------------------\n",
    "    print(\"\\ncombined timestamp gap analysis\")\n",
    "    # excluded the code for timegap analysis\n",
    "    print(\"No timestamp gaps found! (not regarding the different start dates)\")\n",
    "\n",
    "\n",
    "    # ------------------------ outliers (Boxplots) ------------------------\n",
    "    print(\"\\ncombined outlier analysis (all power sources)\")\n",
    "    # generate list of columns of interest\n",
    "    present_cols = set().union(*(df.columns for _, df in dataframes_list))\n",
    "    check_list = Columns.Power.ALL + [Columns.CALC.TOTAL_POWER]\n",
    "    cols_to_plot = [c for c in check_list if c in present_cols]\n",
    "\n",
    "    # count of columns \n",
    "    n_cols = 4\n",
    "    # calculate rows\n",
    "    n_rows = (len(cols_to_plot) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    # convert 2D grid into a 1D List\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col_name in enumerate(cols_to_plot):\n",
    "        ax = axes[i]\n",
    "        plot_data = []\n",
    "        \n",
    "        for country, df in dataframes_list:\n",
    "            if col_name in df.columns:\n",
    "                # only plot the values (for the boxplot the timestamps aren't interesting)\n",
    "                clean_values = df[col_name].values\n",
    "                plot_data.append(pd.DataFrame({'Country': country, 'Value': clean_values}))\n",
    "\n",
    "        if plot_data:\n",
    "            viz_df = pd.concat(plot_data, ignore_index=True)\n",
    "            sns.boxplot(\n",
    "                data=viz_df, \n",
    "                x='Country', \n",
    "                y='Value', \n",
    "                hue='Country', \n",
    "                legend=False, \n",
    "                ax=ax, \n",
    "                palette=colors\n",
    "            )\n",
    "            ax.set_title(col_name, fontsize=11, fontweight='bold')\n",
    "            ax.set_ylabel(\"MW\")\n",
    "            ax.set_xlabel(\"\")\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "        else:\n",
    "            ax.set_visible(False)\n",
    "\n",
    "    for j in range(len(cols_to_plot), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "        \n",
    "    plt.suptitle(\"Distribution & Outliers Comparison \", fontsize=16, y=1.002)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # ------------------------ logical consistency check ------------------------\n",
    "    print(\"\\n[4] Generating Logical Consistency Check...\")\n",
    "    issue_counts = []\n",
    "    \n",
    "    for country, df in dataframes_list:\n",
    "        # count double timestamps\n",
    "        n_dupes = df.index.duplicated().sum()\n",
    "        power_cols = [c for c in Columns.Power.ALL if c in df.columns]\n",
    "        # check if there are some negative power values\n",
    "        n_negatives = (df[power_cols] < 0).sum().sum()\n",
    "        \n",
    "        issue_counts.append({'Country': country, 'Issue': 'Duplicate Rows', 'Count': n_dupes})\n",
    "        issue_counts.append({'Country': country, 'Issue': 'Negative Values', 'Count': n_negatives})\n",
    "    \n",
    "    issues_df = pd.DataFrame(issue_counts)\n",
    "    \n",
    "    # plot duplicates and negatives side by side\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=issues_df, x='Country', y='Count', hue='Issue', palette='Reds')\n",
    "    plt.title(\"Data Logic Errors: Duplicates & Inconsistent Units\", fontsize=16)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# execution\n",
    "analyze_data_quality_combined(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 2.1.4 Data preprocessing pipeline (cleaning steps, handling missing data, outliers strategy, resampling or alignment if needed, feature engineering basics) (20 points)\n",
    "\n",
    "#### 2.1.4.1 Hexbin Plots from Raw Data - Hours of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_hexbin_power_by_state_and_type(\n",
    "    dataframes: list[tuple[str, pd.DataFrame]],\n",
    "    power_columns: list[str],\n",
    "    gridsize=40,\n",
    "    mincnt=5,\n",
    "    TimeAxis=Columns.AXIS.HOURS_OF_DAY,\n",
    "    TimeAxisLabel=\"Hour of Day\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Hexbin grid:\n",
    "    - Columns: states\n",
    "    - Rows: power generation types\n",
    "    - x-axis: hour of day\n",
    "    - y-axis: power [MW]\n",
    "    \"\"\"\n",
    "\n",
    "    n_states = len(dataframes)\n",
    "    n_powers = len(power_columns)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=n_powers,\n",
    "        ncols=n_states,\n",
    "        figsize=(5 * n_states, 3.5 * n_powers),\n",
    "        sharex=True,\n",
    "        sharey=False\n",
    "    )\n",
    "\n",
    "    # Ensure axes is 2D\n",
    "    if n_powers == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "    for col_idx, (country, df) in enumerate(dataframes):\n",
    "        for row_idx, power_col in enumerate(power_columns):\n",
    "\n",
    "            ax = axes[row_idx, col_idx]\n",
    "\n",
    "            if power_col not in df.columns:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            hb = ax.hexbin(\n",
    "                df[TimeAxis],\n",
    "                df[power_col],\n",
    "                gridsize=gridsize,\n",
    "                mincnt=mincnt,\n",
    "                bins=\"log\",\n",
    "                cmap=\"viridis\"\n",
    "            )\n",
    "\n",
    "            # Column titles (states)\n",
    "            if row_idx == 0:\n",
    "                ax.set_title(country, fontsize=12, pad=10)\n",
    "\n",
    "            # Row labels (power types)\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel(power_col.split(\" - \")[0], fontsize=10)\n",
    "\n",
    "            if row_idx == n_powers - 1:\n",
    "                ax.set_xlabel(TimeAxisLabel)\n",
    "\n",
    "    # Colorbar (single global)\n",
    "    cbar = fig.colorbar(\n",
    "        hb,\n",
    "        ax=axes.ravel().tolist(),\n",
    "        orientation=\"vertical\",\n",
    "        fraction=0.015,\n",
    "        pad=0.01\n",
    "    )\n",
    "    cbar.set_label(\"log10(count)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #    Columns.Power.NUCLEAR,\n",
    "    #     Columns.Power.FOSSIL_GAS,\n",
    "    #     Columns.Power.SOLAR,\n",
    "    #     Columns.Power.WIND_ONSHORE,\n",
    "\n",
    "# plot_hexbin_power_by_state_and_type(\n",
    "#     dataframes=dataframes,\n",
    "#     power_columns=Columns.Power.ALL,\n",
    "#     gridsize=50\n",
    "# )\n",
    "\n",
    "# Deactivated due to github html-oversize and not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### 2.1.4.2 Hexbin Plots from Raw Data - column filtered - Hours of the day\n",
    "\n",
    "Power sources not available for at least have of the countries are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hexbin_power_by_state_and_type(\n",
    "    dataframes=dataframes,\n",
    "    power_columns=Columns.Power.ALL_FILT+ [Columns.CALC.TOTAL_POWER],\n",
    "    gridsize=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### 2.1.4.3 Hexplots for raw data - days of the week\n",
    "\n",
    "Hexplots are created for  which show the power production over the days of the week between start and end of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hexbin_power_by_state_and_type(\n",
    "    dataframes=dataframes,\n",
    "    power_columns=Columns.Power.ALL_FILT + [Columns.CALC.TOTAL_POWER],\n",
    "    gridsize=50,\n",
    "    TimeAxis=Columns.AXIS.DAY_OF_WEEK,\n",
    "    TimeAxisLabel=\"Day of Week\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "#### 2.1.4.3 Hexplots for raw data - days of the year\n",
    "\n",
    "Hexplots are created for  which show the power production over the days of the year between start and end of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hexbin_power_by_state_and_type(\n",
    "    dataframes=dataframes,\n",
    "    power_columns=Columns.Power.ALL_FILT+ [Columns.CALC.TOTAL_POWER],\n",
    "    gridsize=50,\n",
    "    TimeAxis=Columns.AXIS.DAY_OF_YEAR,\n",
    "    TimeAxisLabel=\"Day of Year\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Outlier removal was done by fixed upper and lower threshold for two reasons.\n",
    "1. The timely change of power generation to be seen in dayly, weekly patterns would lead to a removal of good data patterns by IQR.\n",
    "2. What kind of unwanted data was removed:\n",
    "    1. Zero power production within total power, not all countries have all types of power sources, but its very unlikely that power production was zero within this time frame.\n",
    "    2. Exrteme spikes in power production e.g. France 2022, January. Several spikes beyond doubled typical power production. According to internet sources (e.g. [Energy Terminal: France's 2022 electricity generation at lowest in 30 years: Report (27.01.2026)](https://www.aa.com.tr/en/energy/electricity/frances-2022-electricity-generation-at-lowest-in-30-years-report/37529?utm_source=chatgpt.com) france hat some maintanence activities for nuclear power plants and saw low production. This might have led to frequency variation in power grid, resulting in high load changes for individual power sources being able to vary the output fast. Taking possible differences in data recording latency, this could lead to spikes due to time shift. This is an asumption, furthermore network frequency data for january 2022 in france was not easily available on most commomn platforms at time of investigation.\n",
    "    3. For all other columns than the calculated total power sources a deep investigation would be necessary to validate the data quality.\n",
    "3. Data removal was done by removing whole lines of total power to be out of limits, leading to a total loss of lines around ~200 which is minor compaired to overall lines per dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_by_fixed_threshold(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    state: str,\n",
    "    thresholds: dict[str, tuple[float | None, float | None]],\n",
    "    min_points: int = 10\n",
    "):\n",
    "    df = df.copy()\n",
    "    mask_keep = pd.Series(True, index=df.index)\n",
    "\n",
    "    report = {\n",
    "        \"state\": state,\n",
    "        \"method\": \"fixed_threshold\",\n",
    "        \"power_sources\": {},\n",
    "        \"summary\": {}\n",
    "    }\n",
    "\n",
    "    for power, (min_val, max_val) in thresholds.items():\n",
    "\n",
    "        if power not in df.columns:\n",
    "            report[\"power_sources\"][power] = {\n",
    "                \"status\": \"skipped (column not found)\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        series = df[power]\n",
    "\n",
    "        valid = series.notna()\n",
    "        n_valid = valid.sum()\n",
    "\n",
    "        if n_valid < min_points:\n",
    "            report[\"power_sources\"][power] = {\n",
    "                \"status\": \"skipped (not enough data)\",\n",
    "                \"points\": int(n_valid)\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        keep = pd.Series(True, index=df.index)\n",
    "\n",
    "        if min_val is not None:\n",
    "            keep &= (series >= min_val) | ~valid\n",
    "        if max_val is not None:\n",
    "            keep &= (series <= max_val) | ~valid\n",
    "\n",
    "        removed = (~keep & valid).sum()\n",
    "\n",
    "        mask_keep &= keep\n",
    "\n",
    "        report[\"power_sources\"][power] = {\n",
    "            \"min_threshold\": min_val,\n",
    "            \"max_threshold\": max_val,\n",
    "            \"total_points\": int(n_valid),\n",
    "            \"removed\": int(removed),\n",
    "            \"removed_pct\": float(100 * removed / n_valid),\n",
    "        }\n",
    "\n",
    "    filtered_df = df.loc[mask_keep].copy()\n",
    "\n",
    "    report[\"summary\"] = {\n",
    "        \"rows_before\": len(df),\n",
    "        \"rows_after\": len(filtered_df),\n",
    "        \"rows_removed\": int((~mask_keep).sum()),\n",
    "        \"rows_removed_pct\": float(100 * (~mask_keep).mean()),\n",
    "    }\n",
    "\n",
    "    return filtered_df, report\n",
    "\n",
    "\n",
    "\n",
    "POWER_THRESHOLDS = {\n",
    "    \"Italy\": {\n",
    "        # Columns.Power.SOLAR: (0, 120000),\n",
    "        # Columns.Power.WIND_ONSHORE: (0, 150000),\n",
    "        # Columns.Power.WIND_OFFSHORE: (0, 90000),\n",
    "        # Columns.Power.NUCLEAR: (0, 100000),\n",
    "        # Columns.Power.FOSSIL_GAS: (0, 200000),\n",
    "        Columns.CALC.TOTAL_POWER: (10000, 50000)\n",
    "    },\n",
    "    \"France\": {\n",
    "        # Columns.Power.SOLAR: (0, 100000),\n",
    "        # Columns.Power.WIND_ONSHORE: (0, 180000),\n",
    "        # Columns.Power.WIND_OFFSHORE: (0, 70000),\n",
    "        # Columns.Power.NUCLEAR: (0, 120000),\n",
    "        # Columns.Power.FOSSIL_GAS: (0, 160000),  \n",
    "        # Columns.Power.FOSSIL_OIL: (0, 50000),\n",
    "        Columns.CALC.TOTAL_POWER: (20000, 100000)\n",
    "    },\n",
    "    \"Germany\": {\n",
    "        # Columns.Power.SOLAR: (0, 80000),\n",
    "        # Columns.Power.WIND_ONSHORE: (0, 200000),\n",
    "        # Columns.Power.WIND_OFFSHORE: (0, 60000),\n",
    "        # Columns.Power.NUCLEAR: (0, 90000),\n",
    "        # Columns.Power.FOSSIL_GAS: (0, 150000),\n",
    "        # Columns.Power.FOSSIL_COAL_DERIVED_GAS: (160, 650),\n",
    "        # Columns.Power.OTHER: (0, 12500),\n",
    "        Columns.CALC.TOTAL_POWER: (20000, 150000)\n",
    "    },\n",
    "    \"Spain\": {\n",
    "        # Columns.Power.SOLAR: (0, 90000),\n",
    "        # Columns.Power.WIND_ONSHORE: (0, 160000),\n",
    "        # Columns.Power.WIND_OFFSHORE: (0, 50000),\n",
    "        # Columns.Power.NUCLEAR: (0, 80000),\n",
    "        # Columns.Power.FOSSIL_GAS: (0, 140000),\n",
    "        # Columns.Power.FOSSIL_BROWN: (150, 100000),\n",
    "        Columns.CALC.TOTAL_POWER: (15000, 110000)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "dataframes_filtered = []\n",
    "reports = []\n",
    "\n",
    "for country, df in dataframes:\n",
    "    # if not ActvnMatrix.is_active(country, PlotOptions.OUTLIER_REMOVAL_FIXED_THRESHOLDS):\n",
    "    #     continue\n",
    "\n",
    "    filtered_df, report = remove_outliers_by_fixed_threshold(\n",
    "        df,\n",
    "        state=country,\n",
    "        thresholds=POWER_THRESHOLDS[country]\n",
    "    )\n",
    "    dataframes_filtered.append((country, filtered_df))\n",
    "    reports.append(report)\n",
    "\n",
    "pprint.pp(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### 2.1.5 Preprocessed vs original comparison (before/after visuals plus commentary on what changed and why) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter_diagnostics_scatter(\n",
    "    df_original: pd.DataFrame,\n",
    "    df_filtered: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    *,\n",
    "    title: str | None = None,\n",
    "    kept_label: str = \"Kept\",\n",
    "    removed_label: str = \"Filtered out\",\n",
    "    kept_color: str = \"tab:blue\",\n",
    "    removed_color: str = \"red\",\n",
    "    kept_alpha: float = 0.4,\n",
    "    removed_alpha: float = 0.9,\n",
    "    kept_size: int = 10,\n",
    "    removed_size: int = 30\n",
    "):\n",
    "    \"\"\"\n",
    "    Scatter diagnostic plot showing which points were filtered out.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_original : pd.DataFrame\n",
    "        Data before filtering.\n",
    "    df_filtered : pd.DataFrame\n",
    "        Data after filtering.\n",
    "    x_col, y_col : str\n",
    "        Columns to plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Align by index ---\n",
    "    df_original = df_original[[x_col, y_col]].dropna()\n",
    "    df_filtered = df_filtered[[x_col, y_col]].dropna()\n",
    "\n",
    "    # Points kept\n",
    "    df_kept = df_original.loc[df_original.index.intersection(df_filtered.index)]\n",
    "\n",
    "    # Points removed\n",
    "    df_removed = df_original.loc[\n",
    "        df_original.index.difference(df_filtered.index)\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Kept points\n",
    "    sns.scatterplot(\n",
    "        data=df_kept,\n",
    "        x=x_col,\n",
    "        y=y_col,\n",
    "        color=kept_color,\n",
    "        alpha=kept_alpha,\n",
    "        s=kept_size,\n",
    "        label=f\"{kept_label} ({len(df_kept)})\"\n",
    "    )\n",
    "\n",
    "    # Removed points\n",
    "    sns.scatterplot(\n",
    "        data=df_removed,\n",
    "        x=x_col,\n",
    "        y=y_col,\n",
    "        color=removed_color,\n",
    "        alpha=removed_alpha,\n",
    "        s=removed_size,\n",
    "        marker=\"x\",\n",
    "        label=f\"{removed_label} ({len(df_removed)})\"\n",
    "    )\n",
    "\n",
    "    plt.xlabel(x_col)\n",
    "    #plt.ylabel(y_col)\n",
    "    plt.title(title or f\"Filter diagnostics: {y_col} vs {x_col}\")\n",
    "    plt.ylabel(\"Total Power [MW]\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in dataframes_filtered:\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"\\nOutlier Removal Report for {country}:\")\n",
    "    print(\"-\" * 40)\n",
    "    plot_filter_diagnostics_scatter(\n",
    "        df_original=dict(dataframes)[country], \n",
    "        df_filtered=df,\n",
    "        x_col=Columns.AXIS.HOURS_OF_DAY,\n",
    "        y_col=Columns.CALC.TOTAL_POWER,\n",
    "        title=f\"Hours of the day - Outlier Removal - {country}\"\n",
    "    )\n",
    "\n",
    "for country, df in dataframes_filtered:\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"\\nOutlier Removal Report for {country}:\")\n",
    "    print(\"-\" * 40)\n",
    "    plot_filter_diagnostics_scatter(\n",
    "        df_original=dict(dataframes)[country], \n",
    "        df_filtered=df,\n",
    "        x_col=Columns.AXIS.DAY_OF_WEEK,\n",
    "        y_col=Columns.CALC.TOTAL_POWER,\n",
    "        title=f\"Day of the week - Outlier Removal - {country}\"\n",
    "    )\n",
    "\n",
    "for country, df in dataframes_filtered:\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"\\nOutlier Removal Report for {country}:\")\n",
    "    print(\"-\" * 40)\n",
    "    plot_filter_diagnostics_scatter(\n",
    "        df_original=dict(dataframes)[country], \n",
    "        df_filtered=df,\n",
    "        x_col=Columns.AXIS.DAY_OF_YEAR,\n",
    "        y_col=Columns.CALC.TOTAL_POWER,\n",
    "        title=f\"Day of the year - Outlier Removal - {country}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_outlier_summary_table(reports: list[dict]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for report in reports:\n",
    "        row = {\n",
    "            \"Country\": report[\"state\"],\n",
    "            **report[\"summary\"]\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows).set_index(\"Country\")\n",
    "\n",
    "outlier_summary_table = build_outlier_summary_table(reports)\n",
    "print(\"\\nOutlier Removal Summary Table:\")\n",
    "print(outlier_summary_table.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### 2.1.4.5 Plot of raw data of a country over whole time range\n",
    "\n",
    "Hexplots are created for  which show the power production over the days of the year between start and end of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_power(df: pd.DataFrame, country: str):\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(Columns.Power.ALL),\n",
    "        ncols=1,\n",
    "        sharex=True,\n",
    "        figsize=(14, 2.5 * len(Columns.Power.ALL))\n",
    "    )\n",
    "\n",
    "    for ax, col in zip(axes, Columns.Power.ALL):\n",
    "        ax.plot(\n",
    "            df.index,\n",
    "            df[col],\n",
    "            color=colors[country],\n",
    "            linewidth=0.6\n",
    "        )\n",
    "        ax.set_title(col, fontsize=11)\n",
    "        ax.set_ylabel(\"MW\")\n",
    "\n",
    "    fig.suptitle(f\"{country} – Raw Power Generation (Hourly)\", fontsize=16)\n",
    "    plt.xlabel(\"Datetime\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for country, df in dataframes:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.TIME_PLOT_RAW_POWER):\n",
    "        continue\n",
    "    #df[Columns.Power.ALL] = df[Columns.Power.ALL].apply( pd.to_numeric, errors='coerce' )\n",
    "    plot_raw_power(df, country)\n",
    "    # plot_raw_overlay(df, country)\n",
    "    print(type(df.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "#### 2.1.4.6 Share of power source by country downsampled to month over all consequtive time\n",
    "\n",
    "This function shall show the individual difference of used power sources and power amount between the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seahorse_share_all_data(df: pd.DataFrame, country_name: str):\n",
    "    \"\"\"\n",
    "    Plot a stacked area chart of all power columns, ignoring order.\n",
    "    \"\"\"\n",
    "    df_graph = df.copy()\n",
    "\n",
    "    # Skip non-existing columns\n",
    "    power_cols = [c for c in Columns.Power.ALL if c in df_graph.columns]\n",
    "    df_graph = df_graph[power_cols]\n",
    "\n",
    "    # Force numeric (extra safety)\n",
    "    df_graph = df_graph.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Monthly aggregation\n",
    "    df_graph = df_graph.resample(\"M\").mean()\n",
    "\n",
    "    if df_graph.empty:\n",
    "        print(f\"No data after resampling for {country_name}\")\n",
    "        return\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(18, 10))\n",
    "\n",
    "    colors = sns.color_palette(\"tab20\", n_colors=len(power_cols))\n",
    "    short_labels = [col.split(\" - \")[0] for col in power_cols]\n",
    "\n",
    "    plt.stackplot(\n",
    "        df_graph.index,\n",
    "        *[df_graph[col].fillna(0) for col in power_cols],\n",
    "        labels=short_labels,\n",
    "        colors=colors,\n",
    "        alpha=0.75\n",
    "    )\n",
    "\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.ylabel(\"Power [MW]\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.title(f\"{country_name} – Monthly Average Power Generation\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes = [\n",
    "#     (\"Italy\", df_italy),\n",
    "#     (\"France\", df_france),\n",
    "#     (\"Germany\", df_germany),\n",
    "#     (\"Spain\", df_spain)\n",
    "# ]\n",
    "\n",
    "for country, df in dataframes_filtered:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.POWER_SHARE_BY_SOURCE):\n",
    "        continue\n",
    "    plot_seahorse_share_all_data(df, country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### 2.1.4.7 Power share of countries over the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seahorse_share_yearly_data(df: pd.DataFrame, country_name: str):\n",
    "    \"\"\"\n",
    "    Plot a stacked area chart showing average daily power profile\n",
    "    over a year (day-of-year).\n",
    "    \"\"\"\n",
    "\n",
    "    df_graph = df.copy()\n",
    "\n",
    "    # Keep only power columns\n",
    "    power_cols = [c for c in Columns.Power.ALL if c in df_graph.columns]\n",
    "    df_graph = df_graph[power_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Daily aggregation - \"D\" daily, \"M\" monthly, \"W-MON\" weekly starting Monday\n",
    "    #df_graph = df_graph.resample(\"W-MON\").mean()\n",
    "\n",
    "    # Add day-of-year\n",
    "    df_graph[\"day_of_year\"] = df_graph.index.dayofyear\n",
    "\n",
    "    # Average over all years → yearly profile\n",
    "    df_graph = df_graph.groupby(\"day_of_year\").mean()\n",
    "\n",
    "    if df_graph.empty:\n",
    "        print(f\"No data after aggregation for {country_name}\")\n",
    "        return\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(18, 10))\n",
    "\n",
    "    colors = sns.color_palette(\"tab20\", n_colors=len(power_cols))\n",
    "    short_labels = [col.split(\" - \")[0] for col in power_cols]\n",
    "\n",
    "    plt.stackplot(\n",
    "        df_graph.index,\n",
    "        *[df_graph[col].fillna(0) for col in power_cols],\n",
    "        labels=short_labels,\n",
    "        colors=colors,\n",
    "        alpha=0.75\n",
    "    )\n",
    "\n",
    "    # plt.stackplot(\n",
    "    #     date=df_graph,\n",
    "    #     x=Columns.AXIS.MONTH_STR,\n",
    "    #     y=power_cols,\n",
    "    #     labels=short_labels,\n",
    "    #     colors=colors,\n",
    "    #     alpha=0.75\n",
    "    # )\n",
    "\n",
    "    plt.ylabel(\"Average Power [MW]\")\n",
    "    plt.xlabel(\"Day of Year\")\n",
    "    plt.title(f\"{country_name} – Average Power Generation Over a Year\")\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in dataframes_filtered:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.POWER_SHARE_BY_SOURCE):\n",
    "        continue\n",
    "    plot_seahorse_share_yearly_data(df, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seahorse_share_weekly_data(df: pd.DataFrame, country_name: str):\n",
    "    \"\"\"\n",
    "    Plot a stacked area chart showing average daily power profile\n",
    "    over a year (day-of-year).\n",
    "    \"\"\"\n",
    "\n",
    "    df_graph = df.copy()\n",
    "\n",
    "    # Keep only power columns\n",
    "    power_cols = [c for c in Columns.Power.ALL if c in df_graph.columns]\n",
    "    df_graph = df_graph[power_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Daily aggregation - \"D\" daily, \"M\" monthly, \"W-MON\" weekly starting Monday\n",
    "    #df_graph = df_graph.resample(\"W-MON\").mean()\n",
    "\n",
    "    # Add day-of-week\n",
    "    df_graph[Columns.AXIS.DAY_OF_WEEK] = df_graph.index.dayofweek + (df_graph.index.hour + df_graph.index.minute / 60) / 24\n",
    "\n",
    "    # Average over all years → yearly profile\n",
    "    df_graph = df_graph.groupby(Columns.AXIS.DAY_OF_WEEK).mean()\n",
    "\n",
    "    if df_graph.empty:\n",
    "        print(f\"No data after aggregation for {country_name}\")\n",
    "        return\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(18, 10))\n",
    "\n",
    "    colors = sns.color_palette(\"tab20\", n_colors=len(power_cols))\n",
    "    short_labels = [col.split(\" - \")[0] for col in power_cols]\n",
    "\n",
    "    plt.stackplot(\n",
    "        df_graph.index,\n",
    "        *[df_graph[col].fillna(0) for col in power_cols],\n",
    "        labels=short_labels,\n",
    "        colors=colors,\n",
    "        alpha=0.75\n",
    "    )\n",
    "\n",
    "    # plt.stackplot(\n",
    "    #     date=df_graph,\n",
    "    #     x=Columns.AXIS.MONTH_STR,\n",
    "    #     y=power_cols,\n",
    "    #     labels=short_labels,\n",
    "    #     colors=colors,\n",
    "    #     alpha=0.75\n",
    "    # )\n",
    "\n",
    "    plt.ylabel(\"Average Power [MW]\")\n",
    "    plt.xlabel(\"Days of week\")\n",
    "    plt.title(f\"{country_name} – Average Power Generation Over a Week\")\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for country, df in dataframes_filtered:\n",
    "    # if not ActvnMatrix.is_active(country, PlotOptions.POWER_SHARE_BY_SOURCE):\n",
    "    #     continue\n",
    "    plot_seahorse_share_weekly_data(df, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seahorse_share_daily_data(df: pd.DataFrame, country_name: str):\n",
    "    \"\"\"\n",
    "    Plot a stacked area chart showing average daily power profile\n",
    "    over a year (day-of-year).\n",
    "    \"\"\"\n",
    "\n",
    "    df_graph = df.copy()\n",
    "\n",
    "    # Keep only power columns\n",
    "    power_cols = [c for c in Columns.Power.ALL if c in df_graph.columns]\n",
    "    df_graph = df_graph[power_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Daily aggregation - \"D\" daily, \"M\" monthly, \"W-MON\" weekly starting Monday\n",
    "    #df_graph = df_graph.resample(\"W-MON\").mean()\n",
    "\n",
    "    # Add hours of day\n",
    "    df_graph[Columns.AXIS.HOURS_OF_DAY] = df_graph.index.hour + df_graph.index.minute / 60\n",
    "\n",
    "    # Average over all years → yearly profile\n",
    "    df_graph = df_graph.groupby(Columns.AXIS.HOURS_OF_DAY).mean()\n",
    "\n",
    "    if df_graph.empty:\n",
    "        print(f\"No data after aggregation for {country_name}\")\n",
    "        return\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(18, 10))\n",
    "\n",
    "    colors = sns.color_palette(\"tab20\", n_colors=len(power_cols))\n",
    "    short_labels = [col.split(\" - \")[0] for col in power_cols]\n",
    "\n",
    "    plt.stackplot(\n",
    "        df_graph.index,\n",
    "        *[df_graph[col].fillna(0) for col in power_cols],\n",
    "        labels=short_labels,\n",
    "        colors=colors,\n",
    "        alpha=0.75\n",
    "    )\n",
    "\n",
    "    # plt.stackplot(\n",
    "    #     date=df_graph,\n",
    "    #     x=Columns.AXIS.MONTH_STR,\n",
    "    #     y=power_cols,\n",
    "    #     labels=short_labels,\n",
    "    #     colors=colors,\n",
    "    #     alpha=0.75\n",
    "    # )\n",
    "\n",
    "    plt.ylabel(\"Average Power [MW]\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.title(f\"{country_name} – Average Power Generation Over a Day\")\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for country, df in dataframes_filtered:\n",
    "    # if not ActvnMatrix.is_active(country, PlotOptions.POWER_SHARE_BY_SOURCE):\n",
    "    #     continue\n",
    "    plot_seahorse_share_daily_data(df, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_total_power_scatter(dataframes: list[tuple[str, pd.DataFrame]]):\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(dataframes),\n",
    "        ncols=1,\n",
    "        figsize=(20, 12),\n",
    "        sharex=True\n",
    "    )\n",
    "\n",
    "    enum_limit = {}\n",
    "\n",
    "    state_cut_line_values = {\n",
    "        \"Italy\": [15000, 50000],\n",
    "        \"France\": [30000, 90000],\n",
    "        \"Germany\": [30000, 90000],\n",
    "        \"Spain\": [18000, 42000]\n",
    "    }\n",
    "\n",
    "    for ax, (country, df) in zip(axes, dataframes):\n",
    "\n",
    "        sns.scatterplot( \n",
    "            data=df,\n",
    "            x=Columns.AXIS.DAY_OF_YEAR,\n",
    "            y=Columns.CALC.TOTAL_POWER,\n",
    "            ax=ax,\n",
    "            color=colors[country],\n",
    "            alpha=0.4,\n",
    "            s=5\n",
    "        )\n",
    "\n",
    "        # Horizontal upper cutoff line\n",
    "        ax.axhline(\n",
    "            y=state_cut_line_values[country][1],\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=1.5,\n",
    "            alpha=0.8\n",
    "        )\n",
    "\n",
    "        # Horizontal lower cutoff line\n",
    "        ax.axhline(\n",
    "            y=state_cut_line_values[country][0],\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=1.5,\n",
    "            alpha=0.8\n",
    "        )\n",
    "\n",
    "        upper_y_offset = 2500\n",
    "        lower_y_offset = -6000\n",
    "\n",
    "        ax.text(\n",
    "            x=10,  # day 10\n",
    "            y=state_cut_line_values[country][1] + upper_y_offset,\n",
    "            s=f\"{state_cut_line_values[country][1]:,.0f} MW\",\n",
    "            color=\"red\",\n",
    "            fontsize=10\n",
    "        )\n",
    "\n",
    "        ax.text(\n",
    "            x=10,  # day 10\n",
    "            y=state_cut_line_values[country][0] + lower_y_offset,\n",
    "            s=f\"{state_cut_line_values[country][0]:,.0f} MW\",\n",
    "            color=\"red\",\n",
    "            fontsize=10\n",
    "        )\n",
    "\n",
    "        # Set consistent y-axis\n",
    "        ax.set_ylim(0, 100000)  # add a small buffer\n",
    "\n",
    "        ax.set_title(f\"Total power generation in {country}\")\n",
    "        ax.set_ylabel(\"Total Power [MW]\")\n",
    "\n",
    "        \n",
    "        # ---- Key: format x-axis to show months ----\n",
    "        # ax.xaxis.set_major_locator(mdates.MonthLocator())  # every month\n",
    "        # ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))  # 'Jan', 'Feb', ...\n",
    "\n",
    "    axes[-1].set_xlabel(\"Day of Year\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_total_power_scatter(dataframes_filtered)\n",
    "\n",
    "    # for feature in Columns.Power.ALL:\n",
    "    #     plt.figure(figsize=[len(dataframes_only), len(Columns.Power.ALL)])\n",
    "    #     sns.scatterplot(\n",
    "    #         data=df,\n",
    "    #         x=Columns.AXIS.DAY_OF_YEAR,\n",
    "    #         y=feature,\n",
    "    #         hue='day_of_week',\n",
    "    #         palette='tab10',\n",
    "    #         alpha=0.6\n",
    "    #     )\n",
    "\n",
    "\n",
    "\n",
    "#df_all = pd.concat([df_italy, df_france, df_germany, df_spain], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_yearly_profiles_seasonal(df, country_name):\n",
    "    df_season = df.copy()\n",
    "\n",
    "    df_season = (\n",
    "        df_season\n",
    "        .groupby([Columns.AXIS.YEAR, Columns.AXIS.SEASON], as_index=False)\n",
    "        .mean(numeric_only=True)\n",
    "    )\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    sns.pointplot(\n",
    "        data=df_season,\n",
    "        x=Columns.AXIS.SEASON,\n",
    "        y=Columns.CALC.TOTAL_POWER,\n",
    "        hue=Columns.AXIS.YEAR,\n",
    "        dodge=True\n",
    "    )\n",
    "    # Set consistent y-axis\n",
    "    plt.ylim(0, 76000)  # add a small buffer\n",
    "\n",
    "    plt.xlabel(\"Season\")\n",
    "    plt.ylabel(\"Average Power [MW]\")\n",
    "    plt.title(f\"{country_name} – Seasonal Electricity Production by Year\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in dataframes_filtered:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.YEARLY_SEASONAL_OVER_YEARS):\n",
    "        continue\n",
    "    plot_yearly_profiles_seasonal(df, country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hourly_profile_by_season(df: pd.DataFrame, country: str):\n",
    "    \"\"\"\n",
    "    Plot the total power consumption over the hours of a day, colored by season.\n",
    "    \"\"\"\n",
    "\n",
    "    df_graph = df.copy()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(14,6))\n",
    "\n",
    "    # sns.scatterplot(\n",
    "    #     data=df,\n",
    "    #     x='hour',\n",
    "    #     y=Columns.CALC.TOTAL_POWER,\n",
    "    #     hue=Columns.AXIS.SEASON,\n",
    "    #     palette=[\"#1f77b4\", \"#2ca02c\", \"#ff7f0e\", \"#d62728\"],\n",
    "    #     alpha=0.5,\n",
    "    #     s=10\n",
    "    # )\n",
    "\n",
    "    # Optional: smooth line per season\n",
    "    sns.lineplot(\n",
    "        data=df_graph,\n",
    "        x=Columns.AXIS.HOURS_OF_DAY,\n",
    "        y=Columns.CALC.TOTAL_POWER,\n",
    "        hue=Columns.AXIS.SEASON,\n",
    "        palette=[\"#1f77b4\", \"#2ca02c\", \"#ff7f0e\", \"#d62728\"],\n",
    "        estimator='mean'\n",
    "    )\n",
    "\n",
    "    plt.title(f\"{country} – Average Hourly Power Consumption by Season\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Total Power [MW]\")\n",
    "    plt.xticks(range(0,25))\n",
    "    plt.legend(title=\"Season\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in dataframes_filtered:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.HOURLY_PLOT_OVER_SEASONS):\n",
    "        continue\n",
    "    plot_hourly_profile_by_season(df, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hexbin_hourly_power(df: pd.DataFrame, country: str):\n",
    "    \"\"\"\n",
    "    Create a hexbin plot per state showing precomputed total power vs hour of the day.\n",
    "    Assumes 'total_power' and 'hour' columns already exist in each dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    hb = plt.hexbin(\n",
    "        x=df[Columns.AXIS.HOURS_OF_DAY],\n",
    "        y=df[Columns.CALC.TOTAL_POWER],\n",
    "        gridsize=48,\n",
    "        cmap='viridis',\n",
    "        mincnt=1,\n",
    "        linewidths=0.5,\n",
    "        edgecolors='grey'\n",
    "    )\n",
    "    plt.colorbar(hb, label='Count of data points')\n",
    "    plt.title(f\"{country} – Total Power Production by Hour (Hexbin)\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Total Power [MW]\")\n",
    "    plt.xticks(range(0,25,1))\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in dataframes_filtered:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.HEXBIN_TOTAL_POWER_HOURLY_DAYTIME_PLOT):\n",
    "        continue\n",
    "    plot_hexbin_hourly_power(df, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_power_hexbins(df: pd.DataFrame, country: str):\n",
    "    df_graph = df.copy()\n",
    "\n",
    "    power_cols = [c for c in Columns.Power.ALL if c in df.columns]\n",
    "\n",
    "    for power in power_cols:\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        hb = plt.hexbin(\n",
    "            x=df_graph[Columns.AXIS.DAY_OF_YEAR],    # x = day of year\n",
    "            y=df_graph[Columns.AXIS.HOURS_OF_DAY],    # y = hour with fraction\n",
    "            C=df_graph[Columns.CALC.TOTAL_POWER],    # color = power\n",
    "            gridsize=100,                            # increase for higher resolution\n",
    "            cmap='viridis',\n",
    "            reduce_C_function=np.mean,     # average in bin\n",
    "            mincnt=1                       # skip empty bins\n",
    "        )\n",
    "        plt.colorbar(hb, label=f\"{power} [MW]\")\n",
    "        plt.xlabel(\"Day of Year\")\n",
    "        plt.ylabel(\"Hour of Day\")\n",
    "        plt.title(f\"{country} – {power} Power Consumption\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in dataframes:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.HEXBIN_TOTAL_POWER_DAILY_YEAR_PLOT):\n",
    "        continue\n",
    "    plot_power_hexbins(df, country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_filter_diagnostics_scatter(\n",
    "#     df_original,\n",
    "#     df_filtered,\n",
    "#     x_col=Columns.AXIS.HOURS_OF_DAY,\n",
    "#     y_col=Columns.CALC.TOTAL_POWER,\n",
    "#     title=\"Total Power vs Hour – Filtered points\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_filter_diagnostics_scatter(\n",
    "#     df_original,\n",
    "#     df_filtered,\n",
    "#     x_col=Columns.AXIS.DAY_OF_YEAR,\n",
    "#     y_col=Columns.CALC.TOTAL_POWER\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_filter_diagnostics_scatter(\n",
    "#     df_original,\n",
    "#     df_filtered,\n",
    "#     x_col=Columns.AXIS.HOURS_OF_DAY,\n",
    "#     y_col=Columns.Power.SOLAR,\n",
    "#     title=\"Solar production – filtered diagnostics\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "## 2.2  B. Visualization and Exploratory Analysis (55 points)\n",
    "\n",
    "1. Time-series visualizations (raw, smoothed, rolling mean or windowed views) (10 points)\n",
    "2. Distribution analysis with histograms and density style plots where applicable (10 points)\n",
    "3. Correlation analysis and heatmaps (Pearson and at least one alternative such as Spearman, with short interpretation) (10 points)\n",
    "4.  Daily or periodic pattern analysis (day-of-week, hour-of-day, seasonality indicators, or test-cycle patterns) (15 points)\n",
    "5.  Summary of observed patterns as short check statements (similar to True/False style) with evidence (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "### 2.2.2 Distribution analysis with histograms and density style plots where applicable (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_all_sources(dataframes_list):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"2.2.2 Distribution analysis\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # identify collumms\n",
    "    check_list = [Columns.CALC.TOTAL_POWER] + Columns.Power.ALL_FILT \n",
    "    cols_to_plot = []\n",
    "    \n",
    "    # loops through data to get a unique list of colums \n",
    "    present_cols = set()\n",
    "    for _, df in dataframes_list: \n",
    "        present_cols.update(df.columns)\n",
    "        \n",
    "    # deletes the column no data is found\n",
    "    for col in check_list:\n",
    "        if col in present_cols:\n",
    "            cols_to_plot.append(col)\n",
    "\n",
    "    # set up grid with 5 colums and calculate the rows\n",
    "    n_cols = 5\n",
    "    n_rows = (len(cols_to_plot) + n_cols - 1) // n_cols\n",
    "    \n",
    "    # width fixed at 20 \n",
    "    # height calculated according to n_rows\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 3 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "\n",
    "    # loop through the colums and generate plots\n",
    "    for i, col_name in enumerate(cols_to_plot):\n",
    "        ax = axes[i]\n",
    "        has_data = False\n",
    "        \n",
    "        # added to adjust the displayed frame\n",
    "        view_min = float('inf')\n",
    "        view_max = float('-inf')\n",
    "        \n",
    "        # loop through the\n",
    "        for country, df in dataframes_list:\n",
    "            if col_name in df.columns:\n",
    "                data = df[col_name].dropna()\n",
    "                \n",
    "                if not data.empty and data.std() > 0:\n",
    "                    # plot the full curve (with cut=0 to stop exactly at min/max data)\n",
    "                    sns.kdeplot(\n",
    "                        data,\n",
    "                        ax=ax,\n",
    "                        label=country,\n",
    "                        color=colors[country], \n",
    "                        fill=True,                      # color the area under the curve\n",
    "                        alpha=0.1,                      # transparent fill\n",
    "                        linewidth=1.5, \n",
    "                        warn_singular=False,            \n",
    "                        cut=0)                          # border 0 (no negative line smoothing)            \n",
    "                    has_data = True\n",
    "                    \n",
    "                    # added to delete the outliers (for better visibility)\n",
    "                    q01 = data.quantile(0.01)\n",
    "                    q99 = data.quantile(0.99)\n",
    "                    \n",
    "                    # added (also for view)\n",
    "                    view_min = min(view_min, q01)\n",
    "                    view_max = max(view_max, q99)\n",
    "\n",
    "        # formatting\n",
    "        # remove repetetive text\n",
    "        clean_title = col_name.replace(\" - Actual Aggregated [MW]\", \"\")\n",
    "        ax.set_title(clean_title, fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "        ax.grid(True, linestyle=':', alpha=0.4)\n",
    "        \n",
    "        # added here are the limits set / cut off\n",
    "        if has_data and view_max > view_min:\n",
    "            ax.set_xlim(view_min, view_max)\n",
    "        \n",
    "        # the legend is only displayed on the first plot\n",
    "        if i == 0:\n",
    "            ax.legend(loc='upper right', fontsize=8, title=\"Country\")\n",
    "        else:\n",
    "            if ax.get_legend(): ax.get_legend().remove()\n",
    "\n",
    "        if not has_data:\n",
    "            ax.text(0.5, 0.5, \"No Data / Constant\", ha='center', fontsize=8, color='gray')\n",
    "\n",
    "    # set the empty plots to no data / constant\n",
    "    for j in range(len(cols_to_plot), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.suptitle(\"Comparative Distribution Analysis (Zoomed into 1st-99th Percentile)\", fontsize=16, y=1.005)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# execute\n",
    "plot_distribution_all_sources(dataframes_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_power_comparison(\n",
    "    df_raw: pd.DataFrame,\n",
    "    df_filtered: pd.DataFrame,\n",
    "    country: str,\n",
    "    colors: dict[str, str],\n",
    "    title_suffix: str = \"Power Generation (Hourly)\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a comparison of raw vs filtered power data for each power source.\n",
    "    \"\"\"\n",
    "\n",
    "    n_sources = len(Columns.Power.ALL)\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=n_sources,\n",
    "        ncols=1,\n",
    "        sharex=True,\n",
    "        figsize=(14, 2.5 * n_sources)\n",
    "    )\n",
    "\n",
    "    for ax, col in zip(axes, Columns.Power.ALL):\n",
    "        # Plot raw data\n",
    "        ax.plot(\n",
    "            df_raw.index,\n",
    "            df_raw[col],\n",
    "            color=\"lightgray\",\n",
    "            linewidth=0.6,\n",
    "            label=\"Raw\"\n",
    "        )\n",
    "\n",
    "        # Plot filtered data\n",
    "        ax.plot(\n",
    "            df_filtered.index,\n",
    "            df_filtered[col],\n",
    "            color=colors.get(country, \"tab:blue\"),\n",
    "            linewidth=0.8,\n",
    "            label=\"Filtered\"\n",
    "        )\n",
    "\n",
    "        # Highlight removed points\n",
    "        removed_idx = df_raw.index.difference(df_filtered.index)\n",
    "        # Keep only valid indices for this column\n",
    "        valid_idx = removed_idx.intersection(df_raw[col].dropna().index)\n",
    "\n",
    "        # Extract x and y as numpy arrays to avoid alignment issues\n",
    "        x_vals = valid_idx.to_numpy()\n",
    "        y_vals = df_raw.loc[valid_idx, col].to_numpy()\n",
    "\n",
    "        if len(x_vals) > 0:\n",
    "            ax.scatter(\n",
    "                x_vals,\n",
    "                y_vals,\n",
    "                color=\"red\",\n",
    "                s=20,\n",
    "                marker=\"x\",\n",
    "                label=\"Removed\"\n",
    "            )\n",
    "\n",
    "        ax.set_title(col, fontsize=11)\n",
    "        ax.set_ylabel(\"MW\")\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        # Avoid duplicate legend entries\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        ax.legend(by_label.values(), by_label.keys(), fontsize=9)\n",
    "\n",
    "    fig.suptitle(f\"{country} – {title_suffix}\", fontsize=16)\n",
    "    plt.xlabel(\"Datetime\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for country, df in dataframes_filtered_regression:\n",
    "#     print(\"=\" * 40)\n",
    "#     print(f\"\\nPower Comparison for {country}:\")\n",
    "#     print(\"-\" * 40)\n",
    "#     plot_power_comparison(\n",
    "#         df_raw=dict(dataframes)[country],\n",
    "#         df_filtered=df,\n",
    "#         country=country,\n",
    "#         colors=colors,\n",
    "#         title_suffix=\"Power Generation – Filtered Diagnostics\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### 2.2.3 Correlation analysis and heatmaps (Pearson and at least one alternative such as Spearman, with short interpretation) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correlations_standard(dataframes_list):\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"2.2.3 CORRELATION ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    for country, df in dataframes_list:\n",
    "        \n",
    "        # select colums\n",
    "        target_cols = Columns.Power.ALL + [Columns.CALC.TOTAL_POWER]\n",
    "        available_cols = [c for c in target_cols if c in df.columns]\n",
    "        \n",
    "        # validate colums (take ony valid ones)\n",
    "        valid_cols = []\n",
    "        for col in available_cols:\n",
    "            if df[col].notna().sum() > 10 and df[col].std() > 0:\n",
    "                valid_cols.append(col)\n",
    "        \n",
    "        # if there are less than 2 colums - correlation not possible\n",
    "        if len(valid_cols) < 2:\n",
    "            print(f\"Skipping {country}: Not enough valid columns.\")\n",
    "            continue\n",
    "\n",
    "        # only validated collums\n",
    "        corr_data = df[valid_cols].copy()\n",
    "        \n",
    "        # split the string at \" - \" and keep only the first part.\n",
    "        #(because otherwise the plots would be to small)\n",
    "        new_names = {}\n",
    "        for col in valid_cols:\n",
    "            if \" - \" in col:\n",
    "                clean_name = col.split(\" - \")[0] \n",
    "            else:\n",
    "                clean_name = col # keep original if no separator found\n",
    "            new_names[col] = clean_name\n",
    "            \n",
    "        corr_data.rename(columns=new_names, inplace=True)\n",
    "\n",
    "        # calculate Matrices\n",
    "        pearson_corr = corr_data.corr(method='pearson')\n",
    "        spearman_corr = corr_data.corr(method='spearman')\n",
    "        \n",
    "        # plot conficturation\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(22, 9))\n",
    "        \n",
    "        # Left: Pearson\n",
    "        sns.heatmap(\n",
    "            pearson_corr, \n",
    "            annot=True, \n",
    "            fmt=\".2f\", \n",
    "            cmap='coolwarm', \n",
    "            vmin=-1, \n",
    "            vmax=1, \n",
    "            center=0, \n",
    "            square=True, \n",
    "            linewidths=0.5, \n",
    "            ax=axes[0],\n",
    "            annot_kws={\"size\": 9})\n",
    "        axes[0].set_title(f\"{country} - Pearson (Linear)\", fontsize=16, fontweight='bold', pad=15)\n",
    "        axes[0].tick_params(axis='both', which='major', labelsize=11)\n",
    "        \n",
    "        # Right: Spearman\n",
    "        sns.heatmap(\n",
    "            spearman_corr, \n",
    "            annot=True, \n",
    "            fmt=\".2f\", \n",
    "            cmap='coolwarm', \n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            center=0,\n",
    "            square=True,\n",
    "            linewidths=0.5, \n",
    "            ax=axes[1],\n",
    "            annot_kws={\"size\": 9})\n",
    "        axes[1].set_title(f\"{country} - Spearman (Rank Order)\", fontsize=16, fontweight='bold', pad=15)\n",
    "        axes[1].tick_params(axis='both', which='major', labelsize=11)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# execute\n",
    "analyze_correlations_standard(dataframes_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "### 2.2.4 Daily or periodic pattern analysis \n",
    "\n",
    "day-of-week\n",
    "hour-of-day\n",
    "seasonality indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_periodic_patterns(dataframes_list):\n",
    "\n",
    "    print(f\"\\n{'='*80}\\n2.2.4 PERIODIC PATTERN ANALYSIS\\n{'='*80}\")\n",
    "    \n",
    "    # only visalize the total pwoer collumn\n",
    "    TARGET = Columns.CALC.TOTAL_POWER\n",
    "\n",
    "    # iteration through all countries\n",
    "    for country, df in dataframes_list:\n",
    "        if TARGET not in df.columns: continue\n",
    "\n",
    "        # copy the data and prepareing it for plotting\n",
    "        pdf = df[[TARGET]].copy()\n",
    "        pdf[Columns.AXIS.HOURS_OF_DAY] = pdf.index.hour\n",
    "        pdf[Columns.AXIS.DAY_OF_WEEK_STR] = pdf.index.day_name()\n",
    "        pdf[Columns.AXIS.MONTH_STR] = pdf.index.month_name()\n",
    "\n",
    "        # layout for the plots\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 4.5))\n",
    "        \n",
    "        # DAILY profile\n",
    "        day_stats = pdf.groupby(Columns.AXIS.HOURS_OF_DAY)[TARGET].agg(['mean', 'std'])\n",
    "        # averaging line\n",
    "        ax1.plot(day_stats.index, \n",
    "                 day_stats['mean'], \n",
    "                 color=colors[country], \n",
    "                 lw=2.5, label='Mean')\n",
    "        # shading between -std / mean / +std\n",
    "        ax1.fill_between(day_stats.index, \n",
    "                         day_stats['mean'] - day_stats['std'], \n",
    "                         day_stats['mean'] + day_stats['std'], \n",
    "                         color=colors[country], \n",
    "                         alpha=0.2)\n",
    "        \n",
    "        # set title and gid\n",
    "        ax1.set(title=f\"{country}: Daily Profile\", \n",
    "                xlabel=\"Hour (0-23)\", \n",
    "                ylabel=\"MW\", \n",
    "                xticks=range(0, 25, 4))\n",
    "        ax1.grid(True, \n",
    "                 ls='--', \n",
    "                 alpha=0.5)\n",
    "\n",
    "        # WEEKLY profile \n",
    "        week_stats = pdf.groupby(Columns.AXIS.DAY_OF_WEEK_STR)[TARGET].agg(['mean', 'std']).reindex(WEEK_ORDER)\n",
    "        # averaging line\n",
    "        ax2.plot(week_stats.index, \n",
    "                 week_stats['mean'], \n",
    "                 color=colors[country], \n",
    "                 lw=2.5, \n",
    "                 label='Mean')\n",
    "        ax2.fill_between(week_stats.index, \n",
    "                         week_stats['mean'] - week_stats['std'], \n",
    "                         week_stats['mean'] + week_stats['std'], \n",
    "                         color=colors[country], \n",
    "                         alpha=0.2)\n",
    "        # shading between -std / mean / +std\n",
    "        ax2.set(title=f\"{country}: Weekly Cycle\", \n",
    "                xlabel=\"\", \n",
    "                ylabel=\"\")\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        ax2.grid(True, ls='--', alpha=0.5)\n",
    "\n",
    "        # SEASONAL tred with bar charts\n",
    "        season_stats = pdf.groupby(Columns.AXIS.MONTH_STR)[TARGET].mean().reindex(MONTH_ORDER)\n",
    "        bars = ax3.bar(season_stats.index, \n",
    "                       season_stats.values, \n",
    "                       color=colors[country], \n",
    "                       alpha=0.7, \n",
    "                       edgecolor='k')\n",
    "        \n",
    "        # mark the month with the maximum production in darkred\n",
    "        if not season_stats.empty:\n",
    "            peak_idx = MONTH_ORDER.index(season_stats.idxmax())\n",
    "            bars[peak_idx].set(color='darkred', alpha=1.0)\n",
    "        \n",
    "        # set up plot\n",
    "        ax3.set(title=f\"{country}: Seasonal Trend\", ylabel=\"\")\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        ax3.grid(axis='y', ls='--', alpha=0.5)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# execute\n",
    "analyze_periodic_patterns(dataframes_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### 2.2.5 Summary of observed patterns\n",
    "\n",
    "#### ITALY\n",
    "\n",
    "1. Significant consumption drop on Weekends (>5%).\n",
    "   -> [TRUE]\n",
    "   -> Weekends are 20.9% lower than Weekdays (Avg: 24.5GW vs 31.0GW).\n",
    "\n",
    "2. Grid load is dominated by Winter heating demand.\n",
    "   -> [FALSE]\n",
    "   -> Summer load is 2.7% higher on average.\n",
    "      Temperature (average): summer max 32, winter min 5\n",
    "\n",
    "3. Strong correlation between Solar Generation and Total Load.\n",
    "   -> [FALSE]\n",
    "   -> Pearson Correlation coefficient is 0.41.\n",
    "      Best correlation is between fossil coal delivered gas and Biomass (0.72).\n",
    "      Also high correlation for Hydro Pumped storage and Reservoirs (0.75).\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "#### FRANCE\n",
    "\n",
    "1. Significant consumption drop on Weekends (>5%).\n",
    "   -> [TRUE]\n",
    "   -> Weekends are 8.0% lower than Weekdays (Avg: 55.6GW vs 60.5GW).\n",
    "\n",
    "2. Grid load is dominated by Winter heating demand.\n",
    "   -> [TRUE]\n",
    "   -> Winter load is 42.5% higher on average.\n",
    "      Temperature (average): summer max 25, winter min 0\n",
    "\n",
    "3. Strong correlation between Solar Generation and Total Load.\n",
    "   -> [FALSE]\n",
    "   -> Pearson Correlation coefficient is -0.12.\n",
    "      Distinct correlation between total power and nuclear (0.9).\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "#### GERMANY\n",
    "\n",
    "1. Significant consumption drop on Weekends (>5%)\n",
    "   -> [TRUE]\n",
    "   -> Weekends are 12.3% lower than Weekdays (Avg: 55.7GW vs 63.5GW)\n",
    "\n",
    "2. Grid load is dominated by Winter heating demand\n",
    "   -> [TRUE]\n",
    "   -> Winter load is 18.0% higher on average\n",
    "      Temperature (average): summer max 20, winter min 1.7\n",
    "\n",
    "3. Strong correlation between Solar Generation and Total Load\n",
    "   -> [FALSE]\n",
    "   -> Pearson Correlation coefficient is 0.37\n",
    "      Good correlation between Wind offshore and onshore (0.64)\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "#### SPAIN\n",
    "\n",
    "1. Significant consumption drop on Weekends (>5%).\n",
    "   -> [TRUE] \n",
    "   -> Weekends are 9.1% lower than Weekdays (Avg: 28.4GW vs 31.2GW)\n",
    "\n",
    "2. Grid load is dominated by Winter heating demand.\n",
    "   -> [FALSE] (Summer/Winter balanced) \n",
    "   -> Summer load is 1.2% higher on average\n",
    "      Temperature (average): summer max 28.6, winter min 10.5\n",
    "\n",
    "3. Strong correlation between Solar Generation and Total Load\n",
    "   -> [TRUE] \n",
    "   -> Pearson Correlation: 0.72.\n",
    "      High correlation due to sunny weather driving both solar output and air conditioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "## 2.3 C. Probability and Event Analysis (45 points)\n",
    "\n",
    "1. Threshold-based probability estimation for events (define event, justify threshold, compute empirical probability) (15 points)\n",
    "2. Cross tabulation analysis for two variables (10 points)\n",
    "3. Conditional probability analysis (at least two meaningful conditional relationships) (15 points)\n",
    "4. Summary of observations and limitations (what could bias these estimates, what assumptions were made) (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "### 2.3.2 Cross tabulation analysis for two variables (10 points)\n",
    "\n",
    "One central message of renewable energy is that windy energy is available in the winter when solar energy is low and otherwise around. This analyse shall show the available of wind and solar against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. Cross-tabulation analysis\n",
    "# -----------------------------\n",
    "def cross_tab_analysis(df, col1, col2, bins1=None, bins2=None, normalize=True):\n",
    "    \"\"\"\n",
    "    Cross-tabulation between two variables (can discretize with bins).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    col1, col2 : str\n",
    "        Columns to cross-tabulate\n",
    "    bins1, bins2 : list or None\n",
    "        Optional bin edges to discretize continuous variables\n",
    "    normalize : bool\n",
    "        Return percentages if True\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ctab : pd.DataFrame\n",
    "    \"\"\"\n",
    "    data1 = pd.cut(df[col1], bins=bins1) if bins1 else df[col1]\n",
    "    data2 = pd.cut(df[col2], bins=bins2) if bins2 else df[col2]\n",
    "    \n",
    "    ctab = pd.crosstab(data1, data2, normalize=\"all\" if normalize else False)\n",
    "    return ctab\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2x2 Cross-tab Heatmap Plot\n",
    "# -----------------------------\n",
    "def plot_cross_tab_heatmaps_2x2(dataframes, solar_col, wind_col, bins=5, cmap=\"viridis\", show_percent=True):\n",
    "    \"\"\"\n",
    "    Plot cross-tab heatmaps for multiple countries in a 2x2 layout.\n",
    "    \"\"\"\n",
    "    n_countries = len(dataframes)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_countries + 1) // 2\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12*n_cols, 10*n_rows))\n",
    "    axes = axes.flatten() if n_countries > 1 else [axes]\n",
    "\n",
    "    for ax, (country, df) in zip(axes, dataframes):\n",
    "        # Compute cross-tab\n",
    "        ctab = cross_tab_analysis(\n",
    "            df,\n",
    "            solar_col,\n",
    "            wind_col,\n",
    "            bins1=bins,\n",
    "            bins2=bins,\n",
    "            normalize=True\n",
    "        )\n",
    "\n",
    "        # Convert to percent if requested\n",
    "        data = ctab * 100 if show_percent else ctab\n",
    "        fmt = \".2f\" if show_percent else \".3f\"\n",
    "        cbar_label = \"Joint probability (%)\" if show_percent else \"Frequency\"\n",
    "\n",
    "        # Plot heatmap on the specific axes\n",
    "        sns.heatmap(\n",
    "            data,\n",
    "            annot=True,\n",
    "            fmt=fmt,\n",
    "            cmap=cmap,\n",
    "            cbar=True,\n",
    "            ax=ax,\n",
    "            linewidths=0.5,\n",
    "            linecolor=\"white\",\n",
    "            cbar_kws={\"label\": cbar_label}\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{country} – Solar & Wind\", fontsize=16, pad=12)\n",
    "        ax.set_xlabel(ctab.columns.name or \"Wind output (binned)\", fontsize=14)\n",
    "        ax.set_ylabel(ctab.index.name or \"Solar output (binned)\", fontsize=14)\n",
    "        ax.tick_params(axis='x', labelsize=12)\n",
    "        ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "    # Hide any unused axes\n",
    "    for ax in axes[n_countries:]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Usage Example\n",
    "# -----------------------------\n",
    "plot_cross_tab_heatmaps_2x2(\n",
    "    dataframes_filtered,\n",
    "    solar_col=\"Solar - Actual Aggregated [MW]\",\n",
    "    wind_col=\"Wind Onshore - Actual Aggregated [MW]\",\n",
    "    bins=5,\n",
    "    cmap=\"viridis\",\n",
    "    show_percent=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "### 2.3.1. Threshold-based probability estimation for events (define event, justify threshold, compute empirical probability) (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_event_probability(df, state, thresholds, plot=False):\n",
    "    report = {\n",
    "        \"state\": state,\n",
    "        \"probabilities\": {},\n",
    "        \"thresholds\": {}\n",
    "    }\n",
    "\n",
    "    for power, (min_val, thresh_type) in thresholds.items():\n",
    "        if power not in df.columns:\n",
    "            report[\"thresholds\"][power] = {\"type\": thresh_type, \"value\": None}\n",
    "            report[\"probabilities\"][power] = None\n",
    "            continue\n",
    "\n",
    "        series = df[power].dropna()\n",
    "\n",
    "        if series.empty:  # <- critical check\n",
    "            report[\"thresholds\"][power] = {\"type\": thresh_type, \"value\": None}\n",
    "            report[\"probabilities\"][power] = None\n",
    "            continue\n",
    "\n",
    "        if thresh_type == \"percentile\":\n",
    "            threshold_val = np.percentile(series, min_val)\n",
    "        else:  # absolute\n",
    "            threshold_val = min_val\n",
    "\n",
    "        event = series >= threshold_val\n",
    "        probability = event.sum() / len(series)\n",
    "\n",
    "        report[\"thresholds\"][power] = {\n",
    "            \"type\": thresh_type,\n",
    "            \"value\": threshold_val\n",
    "        }\n",
    "        report[\"probabilities\"][power] = probability\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define thresholds per power source\n",
    "POWER_THRESHOLDS = {\n",
    "    # Columns.Power.SOLAR: (90, \"percentile\"),          # Top 5% of solar output\n",
    "    Columns.Power.SOLAR: (10000, \"absolute\"),      # Absolute threshold in MW\n",
    "    # Columns.Power.SOLAR: (12000, \"absolute\"),      # Absolute threshold in MW\n",
    "    # Columns.Power.SOLAR: (35000, \"absolute\"),      # Absolute threshold in MW\n",
    "    # Columns.Power.WIND_ONSHORE: (150000, \"absolute\"), # Absolute threshold in MW\n",
    "    # Columns.Power.WIND_OFFSHORE: (10000, \"absolute\"),\n",
    "    Columns.Power.WIND_ONSHORE: (30, \"percentile\"),\n",
    "    Columns.Power.WIND_OFFSHORE: (30, \"percentile\"),\n",
    "    Columns.Power.NUCLEAR: (80, \"percentile\"),\n",
    "    Columns.Power.FOSSIL_GAS: (10_000, \"absolute\")\n",
    "}\n",
    "\n",
    "for country, df in dataframes_filtered:\n",
    "    \n",
    "    report = threshold_event_probability(\n",
    "        df=dict(dataframes)[country],\n",
    "        state=country,\n",
    "        thresholds=POWER_THRESHOLDS,\n",
    "        plot=True\n",
    "    )\n",
    "\n",
    "    # Print probabilities\n",
    "    print(f\"\\nThreshold Event Probabilities for {country}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for source, prob in report[\"probabilities\"].items():\n",
    "        if prob is None:\n",
    "            print(f\"{source}: column not found in data\")\n",
    "        else:\n",
    "            print(f\"{source}: {prob:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 1. Threshold-based probability estimation\n",
    "# -----------------------------\n",
    "def compute_event_probabilities(df, thresholds: dict[str, tuple[float | str]], verbose=True):\n",
    "    \"\"\"\n",
    "    Compute empirical probability of threshold-defined events for each power source.\n",
    "    Handles missing or insufficient data safely.\n",
    "    \"\"\"\n",
    "\n",
    "    report = {\n",
    "        \"probabilities\": {},\n",
    "        \"thresholds\": {},\n",
    "        \"notes\": {}\n",
    "    }\n",
    "\n",
    "    for power, (val, typ) in thresholds.items():\n",
    "\n",
    "        if power not in df.columns:\n",
    "            report[\"probabilities\"][power] = None\n",
    "            report[\"notes\"][power] = \"column not found\"\n",
    "            continue\n",
    "\n",
    "        series = df[power].dropna()\n",
    "\n",
    "        # Handle empty or insufficient data\n",
    "        if len(series) == 0:\n",
    "            report[\"probabilities\"][power] = None\n",
    "            report[\"notes\"][power] = \"no valid data\"\n",
    "            continue\n",
    "\n",
    "        if typ == \"percentile\":\n",
    "            threshold_val = np.percentile(series, val)\n",
    "        else:  # absolute\n",
    "            threshold_val = val\n",
    "\n",
    "        # Define event\n",
    "        event = series >= threshold_val\n",
    "        probability = event.mean()\n",
    "\n",
    "        report[\"thresholds\"][power] = {\n",
    "            \"value\": float(threshold_val),\n",
    "            \"type\": typ\n",
    "        }\n",
    "        report[\"probabilities\"][power] = float(probability)\n",
    "        report[\"notes\"][power] = \"ok\"\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"{power}: threshold={threshold_val:.2f} ({typ}), \"\n",
    "                f\"P(event)={probability:.2%}\"\n",
    "            )\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Conditional probability\n",
    "# -----------------------------\n",
    "def conditional_probability(df, event_col, condition_col, threshold_event, threshold_condition):\n",
    "    \"\"\"\n",
    "    Compute P(event | condition) for two columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    event_col, condition_col : str\n",
    "    threshold_event, threshold_condition : numeric\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Conditional probability\n",
    "    \"\"\"\n",
    "    event = df[event_col] >= threshold_event\n",
    "    condition = df[condition_col] >= threshold_condition\n",
    "\n",
    "    if condition.sum() == 0:\n",
    "        return None\n",
    "\n",
    "    return (event & condition).sum() / condition.sum()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Summary\n",
    "# -----------------------------\n",
    "def summarize_prob_analysis(prob_report, ctab_report=None, conditional_probs=None):\n",
    "    \"\"\"\n",
    "    Print concise summary of probability analysis.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Summary of Probability & Event Analysis ===\\n\")\n",
    "    print(\"Event Probabilities:\")\n",
    "    for source, prob in prob_report[\"probabilities\"].items():\n",
    "        if prob is not None:\n",
    "            print(f\"- {source}: {prob:.2%}\")\n",
    "        else:\n",
    "            print(f\"- {source}: No data\")\n",
    "    \n",
    "    if ctab_report is not None:\n",
    "        print(\"\\nCross-tabulation (sample):\")\n",
    "        print(ctab_report.head())\n",
    "    \n",
    "    if conditional_probs is not None:\n",
    "        print(\"\\nConditional Probabilities:\")\n",
    "        for desc, val in conditional_probs.items():\n",
    "            if val is not None:\n",
    "                print(f\"- {desc}: {val:.2%}\")\n",
    "            else:\n",
    "                print(f\"- {desc}: No data / zero condition count\")\n",
    "    \n",
    "    print(\"\\nLimitations: thresholds are user-defined, independent assumption, missing data not considered.\")\n",
    "\n",
    "\n",
    "\n",
    "for country, df in dataframes_filtered:\n",
    "    # 1. Compute event probabilities\n",
    "    prob_report = compute_event_probabilities(df, POWER_THRESHOLDS)\n",
    "\n",
    "    # 2. Cross-tabulation example\n",
    "    ctab = cross_tab_analysis(df, Columns.Power.SOLAR, Columns.Power.WIND_ONSHORE, bins1=5, bins2=5)\n",
    "\n",
    "    # 3. Conditional probabilities\n",
    "    cond_probs = {\n",
    "        \"P(SOLAR high | WIND_ONSHORE high)\": conditional_probability(\n",
    "            df, Columns.Power.SOLAR, Columns.Power.WIND_ONSHORE, threshold_event=np.percentile(df[Columns.Power.SOLAR], 95),\n",
    "            threshold_condition=100_000\n",
    "        ),\n",
    "        \"P(FOSSIL_GAS high | SOLAR low)\": conditional_probability(\n",
    "            df, Columns.Power.FOSSIL_GAS, Columns.Power.SOLAR, threshold_event=200_000, threshold_condition=np.percentile(df[Columns.Power.SOLAR], 5)\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # 4. Summary\n",
    "    summarize_prob_analysis(prob_report, ctab_report=ctab, conditional_probs=cond_probs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "## 2.4 D. Statistical Theory Applications (45 points)\n",
    "\n",
    "1. Law of Large Numbers demonstration (15 points)\n",
    "2. Central Limit Theorem application (sampling distributions, effect of sample size, interpretation) (25 points)\n",
    "3. Result interpretation and sanity checks (what would invalidate your conclusion, what you verified) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_lln(dataframes_list):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"2.4.1 STATISTICAL THEORY: LAW OF LARGE NUMBERS \")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    TARGET = Columns.CALC.TOTAL_POWER\n",
    "\n",
    "    # grid setup\n",
    "    n_cols = 2\n",
    "    n_rows = (len(dataframes_list) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 6 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (country, df) in enumerate(dataframes_list):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        if TARGET not in df.columns:\n",
    "            ax.text(0.5, 0.5, \"Data Missing\", ha='center')\n",
    "            continue\n",
    "\n",
    "        # calculate mean\n",
    "        # (line to converge to)\n",
    "        population_data = df[TARGET].dropna()\n",
    "        true_mean = population_data.mean()\n",
    "        \n",
    "        # simulate the random sampling\n",
    "        #   the data neets to be shuffeled!\n",
    "        #   if it starts in the morning the first values are to low and then the data isnt convergeing right.\n",
    "        shuffled_samples = population_data.sample(frac=1, random_state=42).values\n",
    "        \n",
    "        # 3. calculating the cumulative mean\n",
    "        #    mean of the first value, the first two, three and so on\n",
    "        #    1/1 (1+2)/2 (1+2+3)/3 (1+2+3+4)/4\n",
    "        cumulative_sum = np.cumsum(shuffled_samples)\n",
    "        #    divide by 1,2,3,4,5.....\n",
    "        sample_sizes = np.arange(1, len(shuffled_samples) + 1)\n",
    "        running_means = cumulative_sum / sample_sizes\n",
    "        \n",
    "        # fix:  plot only the start to see the results\n",
    "        #       else there are too many values to see it converge!\n",
    "        limit_n = 5000 \n",
    "        \n",
    "        # plot the calculated mean ( 1/1 (1+2)/2 (1+2+3)/3 ....)\n",
    "        ax.plot(sample_sizes[:limit_n],     # added limit\n",
    "                running_means[:limit_n],    # added limit\n",
    "                color=colors[country], \n",
    "                linewidth=1.5, \n",
    "                alpha=0.8, \n",
    "                label='Sample Mean')\n",
    "        \n",
    "        # plot the mean line in red, where the data should be convergeint\n",
    "        ax.axhline(true_mean, \n",
    "                   color='black', \n",
    "                   linestyle='--', \n",
    "                   linewidth=2, \n",
    "                   label=f'True Mean ({true_mean:.0f} MW)')\n",
    "        \n",
    "        # format the graph for better visibility\n",
    "        ax.set_title(f\"{country}: Convergence to True Mean\", fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel(\"Sample Size (n)\")\n",
    "        ax.set_ylabel(\"Calculated Mean [MW]\")\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.grid(True, linestyle=':', alpha=0.6)\n",
    "        \n",
    "        # Add text verification\n",
    "        # compare mean at n=10 vs n=5000\n",
    "        mean_10 = running_means[9]\n",
    "        mean_5000 = running_means[limit_n-1]\n",
    "\n",
    "        # for visibility measure the error at 10 samples and 5000 samples to see the converge\n",
    "        error_10 = abs(mean_10 - true_mean)\n",
    "        error_5000 = abs(mean_5000 - true_mean)\n",
    "        stats_text = (f\"Error at n=10:   {error_10:.1f} MW\\n\"\n",
    "                      f\"Error at n=5000: {error_5000:.1f} MW\")\n",
    "        \n",
    "        ax.text(0.5, 0.1, stats_text, transform=ax.transAxes, \n",
    "                fontsize=10, bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "\n",
    "    # hide empty subplots if neccesary\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n INTERPRETATION:\")\n",
    "    print(\" - The jagged line starts wildly volatile because 'n' is small (small sample size).\")\n",
    "    print(\" - As 'n' increases (moving right), the colored line flattens and is getting closer to the true mean.\")\n",
    "    print(\" - This proves larger datasets yield more reliable statistics.\")\n",
    "\n",
    "# execute\n",
    "demonstrate_lln(dataframes_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_clt(dataframes_list):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"2.4.2  CENTRAL LIMIT THEOREM (CLT)\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    TARGET_COL = Columns.CALC.TOTAL_POWER  # Column to analyze\n",
    "    NUM_TRIALS = 2000       # repetition times\n",
    "    SMALL_N    = 1          # small sample size for comparison(must be smaller than 5)\n",
    "    LARGE_N    = 2000       # lagre sample size (smooth)\n",
    "    BINS       = 100        # histogramm resolution (bars)\n",
    "    # ==========================================\n",
    "\n",
    "    for country, df in dataframes_list:\n",
    "        if TARGET_COL not in df.columns: continue\n",
    "        \n",
    "        # prepare the data\n",
    "        population = df[TARGET_COL].dropna().values\n",
    "        true_mean = np.mean(population)\n",
    "        \n",
    "        # SMALL sample size\n",
    "        samples_small = np.random.choice(population, size=(NUM_TRIALS, SMALL_N))\n",
    "        means_small = np.mean(samples_small, axis=1)\n",
    "        \n",
    "        # LARGE sample size\n",
    "        samples_large = np.random.choice(population, size=(NUM_TRIALS, LARGE_N))\n",
    "        means_large = np.mean(samples_large, axis=1)\n",
    "\n",
    "        # plot presettings\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "        \n",
    "        # LEFT plot the original \n",
    "        sns.histplot(\n",
    "            population, \n",
    "            kde=True,               # display the smooth line voer the bars\n",
    "            ax=axes[0], \n",
    "            color='gray', \n",
    "            stat='density', \n",
    "            bins=BINS)\n",
    "        \n",
    "        # settings\n",
    "        axes[0].set_title(f\"{country}: Original Population\", fontweight='bold')\n",
    "        axes[0].set_xlabel(\"Power [MW]\")\n",
    "        axes[0].text(0.95, 0.95, \"Often Irregular\\n(Not Normal)\", transform=axes[0].transAxes, \n",
    "                     ha='right', va='top', bbox=dict(boxstyle=\"round\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "        # MIDDLE SMALL sample size\n",
    "        sns.histplot(\n",
    "            means_small,\n",
    "            kde=True,               # display the smooth line voer the bars\n",
    "            ax=axes[1], \n",
    "            color=colors[country], \n",
    "            stat='density',         # normlaizes height \n",
    "            bins=BINS)\n",
    "        # settings\n",
    "      \n",
    "        axes[1].set_title(f\"Sampling Dist. (N={SMALL_N})\", fontweight='bold')\n",
    "        axes[1].set_xlabel(\"Mean Power [MW]\")\n",
    "        axes[1].axvline(true_mean, color='black', linestyle='--', label='True Mean')\n",
    "        axes[1].legend()\n",
    "\n",
    "        # RIGHT LARGE sample size\n",
    "        sns.histplot(\n",
    "            means_large, \n",
    "            kde=True,               # display the smooth line voer the bars \n",
    "            ax=axes[2], \n",
    "            color=colors[country], \n",
    "            stat='density',         # normlaizes height  \n",
    "            bins=BINS)\n",
    "\n",
    "        axes[2].set_title(f\"Sampling Dist. (N={LARGE_N})\", fontweight='bold')\n",
    "        axes[1].set_xlabel(\"Mean Power [MW]\")\n",
    "        axes[2].axvline(true_mean, color='black', linestyle='--', label='True Mean')\n",
    "        axes[2].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# execute\n",
    "demonstrate_clt(dataframes_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### 2.4.3 Result interpretation and sanity checks (what would invalidate your conclusion, what you\n",
    "verified) (5 points)\n",
    "\n",
    "#### LLN Interpretation\n",
    "\n",
    "The experiment confirmed that the power generation is highly unstable on an hourly basis. But the long-term average is a stable and deterministic value.\n",
    "It demonstrates that a sample size of about 2000 values is required to cancel out the random noise of the chaotic world (like weather, day night cycles) and get a precise estimate of the average\n",
    "\n",
    "#### CLT Interpretation\n",
    "\n",
    "Generally the CTL shows, that we can use the normal distribution even on a dataset, which is non-normal (with two peaks)\n",
    "At N=2000 no significand deviations of the theorem was observed. The convergence to a bell curve was confirmed despite the underlying data doesn’t have a normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "## 2.5  E. Regression and Predictive Modeling (45 points)\n",
    "\n",
    "1. Define a prediction target and features (justify why they make sense) (10 points)\n",
    "2. Linear or polynomial model selection (include rationale and show at least two candidates) (10 points)\n",
    "3. Model fitting and validation (train-test split appropriate for time-series. e.g., time-based split) (15 points)\n",
    "4. Residual analysis and interpretation (errors, bias, failure cases, what to improve next) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_manual(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - ss_res / ss_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_yearly_total_power_trend(\n",
    "    df: pd.DataFrame,\n",
    "    country: str,\n",
    "    degrees=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "):\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- yearly aggregation ---\n",
    "    yearly = (\n",
    "        df\n",
    "        .groupby(Columns.AXIS.MONTH, as_index=False)[Columns.CALC.TOTAL_POWER]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    x = yearly.index.values\n",
    "    y = yearly[Columns.CALC.TOTAL_POWER].values\n",
    "\n",
    "    # numeric axis for stable polynomial fitting\n",
    "    t = np.arange(len(x))\n",
    "    t_fit = np.linspace(t.min(), t.max(), 300)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        s=70,\n",
    "        color=colors[country],\n",
    "        label=\"Yearly average\"\n",
    "    )\n",
    "\n",
    "    max_degree = len(x) - 1\n",
    "\n",
    "    for deg in degrees:\n",
    "        if deg > max_degree:\n",
    "            print(\n",
    "                f\"⚠️  Skipping degree {deg} for {country} \"\n",
    "                f\"(only {len(x)} data points)\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        coeffs = np.polyfit(t, y, deg)\n",
    "        poly = np.poly1d(coeffs)\n",
    "\n",
    "        y_pred = poly(t)\n",
    "        r2 = r2_score_manual(y, y_pred)\n",
    "\n",
    "        plt.plot(\n",
    "            np.interp(t_fit, t, x),\n",
    "            poly(t_fit),\n",
    "            linewidth=2,\n",
    "            label=f\"deg={deg}, R²={r2:.3f}\"\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Average Total Power [MW]\")\n",
    "    plt.title(f\"{country} – Yearly Power Production Trend\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in dataframes_filtered:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.TREND_TOTAL_POWER_OVER_YEARS):\n",
    "        continue\n",
    "    plot_yearly_total_power_trend(df, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_hourly_polynomial_comparison(\n",
    "    df: pd.DataFrame,\n",
    "    country: str,\n",
    "    degrees=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
    "):\n",
    "    df = df.copy()\n",
    "\n",
    "    x = df[Columns.AXIS.HOURS_OF_DAY].values\n",
    "    y = df[Columns.CALC.TOTAL_POWER].values\n",
    "\n",
    "    # Clean NaNs\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x, y = x[mask], y[mask]\n",
    "\n",
    "    x_fit = np.linspace(0, 23, 300)\n",
    "\n",
    "    plt.figure(figsize=(13, 7))\n",
    "\n",
    "    # Raw data\n",
    "    sns.scatterplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        alpha=0.25,\n",
    "        s=10,\n",
    "        color=colors[country],\n",
    "        label=\"Hourly observations\"\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for deg in degrees:\n",
    "        coeffs = np.polyfit(x, y, deg)\n",
    "        poly = np.poly1d(coeffs)\n",
    "\n",
    "        y_pred = poly(x)\n",
    "        r2 = r2_score_manual(y, y_pred)\n",
    "\n",
    "        results.append((deg, r2))\n",
    "\n",
    "        plt.plot(\n",
    "            x_fit,\n",
    "            poly(x_fit),\n",
    "            linewidth=2,\n",
    "            label=f\"deg={deg}, R²={r2:.3f}\"\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Total Power [MW]\")\n",
    "    plt.title(f\"{country} – Polynomial Regression Comparison\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Console report\n",
    "    print(f\"\\nPolynomial model comparison for {country}\")\n",
    "    print(\"-\" * 40)\n",
    "    for deg, r2 in results:\n",
    "        print(f\"Degree {deg}: R² = {r2:.4f}\")\n",
    "\n",
    "\n",
    "def plot_hourly_total_power_regression(df: pd.DataFrame, country: str, degree: int = 6):\n",
    "    df = df.copy()\n",
    "\n",
    "    x = df[Columns.AXIS.HOURS_OF_DAY].values\n",
    "    y = df[Columns.CALC.TOTAL_POWER].values\n",
    "\n",
    "    # Remove NaNs\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x, y = x[mask], y[mask]\n",
    "\n",
    "    # Polynomial fit\n",
    "    coeffs = np.polyfit(x, y, degree)\n",
    "    poly = np.poly1d(coeffs)\n",
    "\n",
    "    x_fit = np.linspace(0, 23, 200)\n",
    "    y_fit = poly(x_fit)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        alpha=0.25,\n",
    "        s=10,\n",
    "        color=colors[country],\n",
    "        label=\"Hourly observations\"\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        x_fit,\n",
    "        y_fit,\n",
    "        color=\"black\",\n",
    "        linewidth=2.5,\n",
    "        label=f\"Polynomial regression (deg={degree})\"\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Total Power [MW]\")\n",
    "    plt.title(f\"{country} – Daily Power Profile (Polynomial Regression)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in dataframes_filtered:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.HOURLY_TOTAL_POWER_REGRESSION):\n",
    "        continue\n",
    "    plot_hourly_total_power_regression(df, country)\n",
    "    plot_hourly_polynomial_comparison(df, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_trend_regression(\n",
    "    monthly: pd.DataFrame,\n",
    "    country: str,\n",
    "    degrees=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "):\n",
    "    x = monthly[Columns.AXIS.MONTH].values\n",
    "    y = monthly[Columns.CALC.TOTAL_POWER].values\n",
    "\n",
    "    x_fit = np.linspace(x.min(), x.max(), 300)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Raw monthly trend\n",
    "    sns.scatterplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        s=60,\n",
    "        alpha=0.8,\n",
    "        color=colors[country],\n",
    "        label=\"Monthly mean\"\n",
    "    )\n",
    "\n",
    "    for deg in degrees:\n",
    "        coeffs = np.polyfit(x, y, deg)\n",
    "        poly = np.poly1d(coeffs)\n",
    "\n",
    "        y_pred = poly(x)\n",
    "        r2 = r2_score_manual(y, y_pred)\n",
    "\n",
    "        plt.plot(\n",
    "            x_fit,\n",
    "            poly(x_fit),\n",
    "            linewidth=2,\n",
    "            label=f\"deg={deg}, R²={r2:.3f}\"\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Time (months since start)\")\n",
    "    plt.ylabel(\"Total Power [MW]\")\n",
    "    plt.title(f\"{country} – Monthly Power Trend Regression\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in dataframes_filtered:\n",
    "    if not ActvnMatrix.is_active(country, PlotOptions.TREND_TOTAL_POWER_OVER_MONTHS):\n",
    "        continue\n",
    "    plot_monthly_trend_regression(df, country)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
